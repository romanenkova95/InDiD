model:
  input_dim: 784
  rnn_hid_dim: 32
  num_layers: 1
  wnd_dim: 8
  window_1: 8
  window_2: 8

learning:
  batch_size: 64
  lr: 0.0003
  epochs: 200
  critic_iters: 5
  weight_clip: 0.1
  weight_decay: 0.
  grad_clip: 10.

loss:
  lambda_real: 0.01
  lambda_ae: 0.001
  sqdist: 10

predictions:
  scale: 100

early_stopping:
  monitor: "val_mmd2_real_D"
  min_delta: 0.00001
  patience: 5