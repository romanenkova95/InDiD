model:
  input_dim: 28
  rnn_hid_dim: 8
  num_layers: 1
  wnd_dim: 3
  window_1: 3
  window_2: 3

learning:
  batch_size: 64
  lr: 0.0001
  epochs: 200
  critic_iters: 5
  weight_clip: 0.1
  weight_decay: 0.
  grad_clip: 10.

loss:
  lambda_real: 1
  lambda_ae: 0.2
  sqdist: 2

predictions:
  scale: 5

early_stopping:
  monitor: "val_mmd2_real_D"
  min_delta: 0.00001
  patience: 5