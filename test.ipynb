{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "768d3303",
   "metadata": {},
   "source": [
    "# Reproducing original experiments with KL-CPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "32bf215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sklearn.metrics\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import mmd_util\n",
    "from data_loader import DataLoader\n",
    "from optim import Optim\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7dbaa4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetG(nn.Module):\n",
    "    def __init__(self, args, data):\n",
    "        super(NetG, self).__init__()\n",
    "        self.wnd_dim = args['wnd_dim']\n",
    "        self.var_dim = data.var_dim\n",
    "        self.D = data.D\n",
    "        self.RNN_hid_dim = args['RNN_hid_dim']\n",
    "\n",
    "        self.rnn_enc_layer = nn.GRU(self.var_dim, self.RNN_hid_dim, num_layers=1, batch_first=True)\n",
    "        self.rnn_dec_layer = nn.GRU(self.var_dim, self.RNN_hid_dim, num_layers=1, batch_first=True)\n",
    "        self.fc_layer = nn.Linear(self.RNN_hid_dim, self.var_dim)\n",
    "\n",
    "    # X_p:   batch_size x wnd_dim x var_dim (Encoder input)\n",
    "    # X_f:   batch_size x wnd_dim x var_dim (Decoder input)\n",
    "    # h_t:   1 x batch_size x RNN_hid_dim\n",
    "    # noise: 1 x batch_size x RNN_hid_dim\n",
    "    def forward(self, X_p, X_f, noise):\n",
    "        X_p_enc, h_t = self.rnn_enc_layer(X_p)\n",
    "        X_f_shft = self.shft_right_one(X_f)\n",
    "        hidden = h_t + noise\n",
    "        Y_f, _ = self.rnn_dec_layer(X_f_shft, hidden)\n",
    "        output = self.fc_layer(Y_f)\n",
    "        return output\n",
    "\n",
    "    def shft_right_one(self, X):\n",
    "        X_shft = X.clone()\n",
    "        X_shft[:, 0, :].data.fill_(0)\n",
    "        X_shft[:, 1:, :] = X[:, :-1, :]\n",
    "        return X_shft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5e5a22d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetD(nn.Module):\n",
    "    def __init__(self, args, data):\n",
    "        super(NetD, self).__init__()\n",
    "\n",
    "        self.wnd_dim = args['wnd_dim']\n",
    "        self.var_dim = data.var_dim\n",
    "        self.D = data.D\n",
    "        self.RNN_hid_dim = args['RNN_hid_dim']\n",
    "\n",
    "        self.rnn_enc_layer = nn.GRU(self.var_dim, self.RNN_hid_dim, batch_first=True)\n",
    "        self.rnn_dec_layer = nn.GRU(self.RNN_hid_dim, self.var_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X_enc, _ = self.rnn_enc_layer(X)\n",
    "        X_dec, _ = self.rnn_dec_layer(X_enc)\n",
    "        return X_enc, X_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45c12230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y, L should be numpy array\n",
    "def valid_epoch(loader, data, netD, batch_size, Y_true, L_true):\n",
    "    netD.eval()\n",
    "    Y_pred = []\n",
    "    for inputs in loader.get_batches(data, batch_size, shuffle=False):\n",
    "        X_p, X_f = inputs[0], inputs[1]\n",
    "        batch_size = X_p.size(0)\n",
    "\n",
    "        X_p_enc, _ = netD(X_p)\n",
    "        X_f_enc, _ = netD(X_f)\n",
    "        Y_pred_batch = mmd_util.batch_mmd2_loss(X_p_enc, X_f_enc, sigma_var)\n",
    "        Y_pred.append(Y_pred_batch.data.cpu().numpy())\n",
    "        \n",
    "    Y_pred = np.concatenate(Y_pred, axis=0)\n",
    "\n",
    "    L_pred = Y_pred\n",
    "    fp_list, tp_list, thresholds = sklearn.metrics.roc_curve(L_true, L_pred)\n",
    "    auc = sklearn.metrics.auc(fp_list, tp_list)\n",
    "    eval_dict = {'Y_pred': Y_pred,\n",
    "                 'L_pred': L_pred,\n",
    "                 'Y_true': Y_true,\n",
    "                 'L_true': L_true,\n",
    "                 'mse': -1, 'mae': -1, 'auc': auc}\n",
    "    netD.train()\n",
    "    return eval_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9faecec",
   "metadata": {},
   "source": [
    "## Passing default arguments as a dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba280dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args['data_path'] = '/home/eromanenkova/Intern_CPD/Alex/new_code/klcpd_code/data/beedance/beedance-2.mat'\n",
    "args['trn_ratio'] = 0.6\n",
    "args['val_ratio'] = 0.8\n",
    "args['gpu'] = 0\n",
    "args['cuda'] = True\n",
    "args['random_seed'] = 1126\n",
    "args['wnd_dim'] = 10\n",
    "args['sub_dim'] = 1\n",
    "args['RNN_hid_dim'] = 10\n",
    "args['batch_size'] = 64\n",
    "args['max_iter'] = 100\n",
    "args['optim'] = 'adam'\n",
    "args['lr'] = 3e-4\n",
    "args['weight_decay'] = 0.\n",
    "args['momentum'] = 0.\n",
    "args['grad_clip'] = 10\n",
    "args['eval_freq'] = 50\n",
    "args['CRITIC_ITERS'] = 5\n",
    "args['weight_clip'] = .1\n",
    "args['lambda_ae'] = 0.001\n",
    "args['lambda_real'] = 0.1\n",
    "args['save_path'] = '/home/eromanenkova/Intern_CPD/Alex/new_code/klcpd_code/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e46f8338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/eromanenkova/Intern_CPD/Alex/new_code/klcpd_code/data/beedance/beedance-2.mat'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args['data_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc712648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU device 0\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(args['save_path']):\n",
    "    os.mkdir(args['save_path'])\n",
    "assert(os.path.isdir(args['save_path']))\n",
    "# assert(args.sub_dim == 1)\n",
    "\n",
    "#XXX For Yahoo dataset, trn_ratio=0.50, val_ratio=0.75\n",
    "if 'yahoo' in args['data_path']:\n",
    "    args['trn_ratio'] = 0.50\n",
    "    args['val_ratio'] = 0.75\n",
    "\n",
    "# ========= Setup GPU device and fix random seed=========#\n",
    "if torch.cuda.is_available():\n",
    "    args['cuda'] = True\n",
    "    torch.cuda.set_device(args['gpu'])\n",
    "    print('Using GPU device', torch.cuda.current_device())\n",
    "else:\n",
    "    raise EnvironmentError(\"GPU device not available!\")\n",
    "    \n",
    "np.random.seed(seed=args['random_seed'])\n",
    "random.seed(args['random_seed'])\n",
    "torch.manual_seed(args['random_seed'])\n",
    "torch.cuda.manual_seed(args['random_seed'])\n",
    "# [INFO] cudnn.benckmark=True enable cudnn auto-tuner to find the best algorithm to use for your hardware\n",
    "# [INFO] benchmark mode is good whenever input sizes of network do not vary much!!!\n",
    "# [INFO] https://discuss.pytorch.org/t/what-does-torch-backends-cudnn-benchmark-do/5936\n",
    "# [INFO] https://discuss.pytorch.org/t/pytorch-performance/3079/2\n",
    "cudnn.benchmark == True\n",
    "\n",
    "# [INFO} For reproducibility and debugging, set cudnn.enabled=False\n",
    "# [INFO] Some operations are non-deterministic when cudnn.enabled=True\n",
    "# [INFO] https://discuss.pytorch.org/t/non-determinisic-results/459\n",
    "# [INFO] https://discuss.pytorch.org/t/non-reproducible-result-with-gpu/1831\n",
    "cudnn.enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0820446",
   "metadata": {},
   "source": [
    "## Look at original data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18dd6c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import math\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class DataLoader(object):\n",
    "    def __init__(self, args, trn_ratio=0.6, val_ratio=0.8):\n",
    "        self.cuda = args['cuda']\n",
    "        #self.cuda = True\n",
    "        self.data_path = args['data_path']\n",
    "        self.p_wnd_dim = 25\n",
    "        self.f_wnd_dim = args['wnd_dim']\n",
    "        self.sub_dim = args['sub_dim']\n",
    "        self.batch_size = args['batch_size']\n",
    "\n",
    "        # load data\n",
    "        self.load_data(trn_ratio=trn_ratio, val_ratio=val_ratio)\n",
    "\n",
    "        # prepare data\n",
    "        self.prepare_data()\n",
    "\n",
    "        # split data into trn/val/tst set\n",
    "        self.split_data()\n",
    "\n",
    "    # load data\n",
    "    def load_data(self, trn_ratio=0.6, val_ratio=0.8):\n",
    "        assert(os.path.lexists(self.data_path))\n",
    "        dataset = sio.loadmat(self.data_path)\n",
    "        self.Y = dataset['Y']                                   # Y: time series data, time length x number of variables\n",
    "        self.L = dataset['L']                                   # L: label of anomaly, time length x 1\n",
    "        self.T, self.D = self.Y.shape                           # T: time length; D: variable dimension\n",
    "        self.n_trn = int(np.ceil(self.T * trn_ratio))           # n_trn: first index of val set\n",
    "        self.n_val = int(np.ceil(self.T * val_ratio))           # n_val: first index of tst set\n",
    "        self.var_dim = self.D * self.sub_dim\n",
    "        \n",
    "        return dataset\n",
    "\n",
    "    # prepare subspace data (Hankel matrix)\n",
    "    def prepare_data(self):\n",
    "        # T x D x sub_dim\n",
    "        self.Y_subspace = np.zeros((self.T, self.D, self.sub_dim))\n",
    "        for t in range(self.sub_dim, self.T):\n",
    "            for d in range(self.D):\n",
    "                self.Y_subspace[t, d, :] = self.Y[t - self.sub_dim + 1 : t + 1, d].flatten()\n",
    "\n",
    "        # Y_subspace is now T x (D x sub_dim)\n",
    "        self.Y_subspace = self.Y_subspace.reshape(self.T, -1)\n",
    "        \n",
    "        return self.Y_subspace\n",
    "\n",
    "    # split data into trn/val/tst set\n",
    "    def split_data(self):\n",
    "        trn_set_idx = range(self.p_wnd_dim, self.n_trn)\n",
    "        val_set_idx = range(self.n_trn, self.n_val)\n",
    "        tst_set_idx = range(self.n_val, self.T)\n",
    "        print('n_trn ', len(trn_set_idx), 'n_val ', len(val_set_idx), 'n_tst ', len(tst_set_idx))\n",
    "        self.trn_set = self.__batchify(trn_set_idx)\n",
    "        self.val_set = self.__batchify(val_set_idx)\n",
    "        self.tst_set = self.__batchify(tst_set_idx)\n",
    "        \n",
    "        return self.trn_set, self.tst_set, self.val_set\n",
    "\n",
    "    # convert augmented data in Hankel matrix to origin time series\n",
    "    # input: X_f, whose shape is batch_size x seq_len x (D*sub_dim)\n",
    "    # output: Y_t, whose shape is batch_size x D\n",
    "    def repack_data(self, X_f, batch_size):\n",
    "        Y_t = X_f[:, 0, :].contiguous().view(batch_size, self.D, self.sub_dim)\n",
    "        return Y_t[:, :, -1]\n",
    "\n",
    "    def __batchify(self, idx_set):\n",
    "        n = len(idx_set)\n",
    "        L = torch.zeros((n, 1))                             # anomaly label\n",
    "        Y = torch.zeros((n, self.D))                        # true signal\n",
    "        X_p = torch.zeros((n, self.p_wnd_dim, self.var_dim))  # past window buffer\n",
    "        X_f = torch.zeros((n, self.f_wnd_dim, self.var_dim))  # future window buffer\n",
    "\n",
    "        # XXX: dirty trick to augment the last buffer\n",
    "        data = np.concatenate((self.Y_subspace, self.Y_subspace[-self.f_wnd_dim:, :]))\n",
    "        for i in range(n):\n",
    "            l = idx_set[i] - self.p_wnd_dim\n",
    "            m = idx_set[i]\n",
    "            u = idx_set[i] + self.f_wnd_dim\n",
    "            X_p[i, :, :] = torch.from_numpy(data[l:m, :])\n",
    "            X_f[i, :, :] = torch.from_numpy(data[m:u, :])\n",
    "            Y[i, :] = torch.from_numpy(self.Y[m, :])\n",
    "            L[i] = torch.from_numpy(self.L[m])\n",
    "        return {'X_p': X_p, 'X_f': X_f, 'Y': Y, 'L': L}\n",
    "\n",
    "    def get_batches(self, data_set, batch_size, shuffle=False):\n",
    "        X_p, X_f = data_set['X_p'], data_set['X_f']\n",
    "        Y, L = data_set['Y'], data_set['L']\n",
    "        length = len(Y)\n",
    "        if shuffle:\n",
    "            index = torch.randperm(length)\n",
    "        else:\n",
    "            index = torch.LongTensor(range(length))\n",
    "        s_idx = 0\n",
    "        while (s_idx < length):\n",
    "            e_idx = min(length, s_idx + batch_size)\n",
    "            excerpt = index[s_idx:e_idx]\n",
    "            X_p_batch, X_f_batch = X_p[excerpt], X_f[excerpt]\n",
    "            Y_batch, L_batch = Y[excerpt], L[excerpt]\n",
    "            if self.cuda:\n",
    "                X_p_batch = X_p_batch.cuda()\n",
    "                X_f_batch = X_f_batch.cuda()\n",
    "                Y_batch = Y_batch.cuda()\n",
    "                L_batch = L_batch.cuda()\n",
    "\n",
    "            data = [Variable(X_p_batch),\n",
    "                    Variable(X_f_batch),\n",
    "                    Variable(Y_batch),\n",
    "                    Variable(L_batch)]\n",
    "            yield data\n",
    "            s_idx += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7f8a995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_trn  650 n_val  225 n_tst  224\n"
     ]
    }
   ],
   "source": [
    "Data = DataLoader(args=args, trn_ratio=args['trn_ratio'], val_ratio=args['val_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad7e6f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dataset = Data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7da0f18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial seq (Y): [[0.46881138 0.24722328 0.59424341]\n",
      " [0.47624722 0.24586509 0.53681638]\n",
      " [0.47491192 0.19903185 0.51054309]\n",
      " ...\n",
      " [0.22467969 0.54632052 0.28420598]\n",
      " [0.25351394 0.51194649 0.80778465]\n",
      " [0.26821072 0.56950183 0.44725902]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1124, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('initial seq (Y):', loaded_dataset['Y'])\n",
    "loaded_dataset['Y'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a439a418",
   "metadata": {},
   "source": [
    "\"Fishkiller\": \n",
    "\n",
    "    'Y' - 1 sequence with 1D-observations, length T=45175, shape=(45175, 1)\n",
    "    'L' - corresponding labels, shape=(45175, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f3b0d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial labels (L): [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1124, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('initial labels (L):',loaded_dataset['L'])\n",
    "loaded_dataset['L'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c65b60da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  47,  100,  160,  209,  265,  337,  370,  416,  449,  494,  550,\n",
       "         594,  636,  671,  713,  778,  834,  890,  942,  986, 1045, 1106]),)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(loaded_dataset['L'].squeeze() == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3cfb617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "Y_subspace = Data.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "112b3fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1124, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_subspace.shape # Y_subspace has the same shape (initial seq_len, subspace_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2641730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "225e3eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.87493411]\n",
      " ...\n",
      " [82.41881436]\n",
      " [80.94807863]\n",
      " [78.80273557]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_subspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fafae179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_trn  650 n_val  225 n_tst  224\n"
     ]
    }
   ],
   "source": [
    "trn_set, tst_set, val_set = Data.split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f29ac7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([650, 25, 3])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_set['X_p'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dc829b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([650, 10, 3])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_set['X_f'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d2009ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([650, 3])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_set['Y'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "27a15cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([650, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_set['L'].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e43916",
   "metadata": {},
   "source": [
    "## Get DataLoader and the nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4406b414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_trn  650 n_val  225 n_tst  224\n"
     ]
    }
   ],
   "source": [
    "Data = DataLoader(args=args, trn_ratio=args['trn_ratio'], val_ratio=args['val_ratio'])\n",
    "netG = NetG(args, Data)\n",
    "netD = NetD(args, Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0b38f43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([650, 25, 3])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.trn_set['X_p'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ef0a536b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([650, 10, 3])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.trn_set['X_f'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b7f30a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data.trn_set['L']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82601229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetG(\n",
      "  (rnn_enc_layer): GRU(3, 10, batch_first=True)\n",
      "  (rnn_dec_layer): GRU(3, 10, batch_first=True)\n",
      "  (fc_layer): Linear(in_features=10, out_features=3, bias=True)\n",
      ")\n",
      "NetD(\n",
      "  (rnn_enc_layer): GRU(3, 10, batch_first=True)\n",
      "  (rnn_dec_layer): GRU(10, 3, batch_first=True)\n",
      ")\n",
      "netG has number of parameters: 933\n",
      "netD has number of parameters: 585\n"
     ]
    }
   ],
   "source": [
    "if args['cuda']:\n",
    "    netG.cuda()\n",
    "    netD.cuda()\n",
    "    \n",
    "netG_params_count = sum([p.nelement() for p in netG.parameters()])\n",
    "netD_params_count = sum([p.nelement() for p in netD.parameters()])\n",
    "print(netG)\n",
    "print(netD)\n",
    "print('netG has number of parameters: %d' % (netG_params_count))\n",
    "print('netD has number of parameters: %d' % (netD_params_count))\n",
    "one = torch.tensor(1, dtype=torch.float)\n",
    "\n",
    "mone = one * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e9200d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerG = Optim(netG.parameters(),\n",
    "                   'adam',\n",
    "                   lr=3e-4,\n",
    "                   grad_clip=10.0,\n",
    "                   weight_decay=0.,\n",
    "                   momentum=0.0)\n",
    "\n",
    "optimizerD = Optim(netD.parameters(),\n",
    "                   'adam',\n",
    "                   lr=3e-4,\n",
    "                   grad_clip=10.0,\n",
    "                   weight_decay=0.,\n",
    "                   momentum=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "711d929e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma_var: tensor([0.0476, 0.0952, 0.1904, 0.3808, 0.7615], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sigma_list = mmd_util.median_heuristic(Data.Y_subspace, beta=.5)\n",
    "sigma_var = torch.cuda.FloatTensor(sigma_list)\n",
    "print('sigma_var:', sigma_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd311c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_batchs 11 batch_size 64\n"
     ]
    }
   ],
   "source": [
    "# ========= Main loop for adversarial training kernel with negative samples X_f + noise =========#\n",
    "Y_val = Data.val_set['Y'].numpy()\n",
    "L_val = Data.val_set['L'].numpy()\n",
    "Y_tst = Data.tst_set['Y'].numpy()\n",
    "L_tst = Data.tst_set['L'].numpy()\n",
    "\n",
    "n_batchs = int(math.ceil(len(Data.trn_set['Y']) / float(args['batch_size'])))\n",
    "print('n_batchs', n_batchs, 'batch_size', args['batch_size'])\n",
    "\n",
    "lambda_ae = args['lambda_ae']\n",
    "lambda_real = args['lambda_real']\n",
    "gen_iterations = 0\n",
    "total_time = 0.\n",
    "best_epoch = -1\n",
    "best_val_mae = 1e+6\n",
    "best_val_auc = -1\n",
    "best_tst_auc = -1\n",
    "best_mmd_real = 1e+6\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6330d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training: lambda_ae 0.001 lambda_real 0.1 weight_clip 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eromanenkova/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:32: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1/  100] [    6/   11] [     1] D_mmd2 3.9696e+00 G_mmd2 4.0587e+00 mmd2_real 8.8606e-01 real_L2 0.250475 fake_L2 0.154572\n",
      "[    2/  100] [    6/   11] [     2] D_mmd2 4.1227e+00 G_mmd2 4.0589e+00 mmd2_real 9.3354e-01 real_L2 0.258504 fake_L2 0.137592\n",
      "[    3/  100] [    6/   11] [     3] D_mmd2 4.2668e+00 G_mmd2 4.1920e+00 mmd2_real 8.6151e-01 real_L2 0.275639 fake_L2 0.134515\n",
      "[    4/  100] [    6/   11] [     4] D_mmd2 4.2493e+00 G_mmd2 4.3544e+00 mmd2_real 8.2608e-01 real_L2 0.264977 fake_L2 0.125769\n",
      "[    5/  100] [    6/   11] [     5] D_mmd2 4.4375e+00 G_mmd2 4.3762e+00 mmd2_real 8.6682e-01 real_L2 0.284731 fake_L2 0.125974\n",
      "[    6/  100] [    6/   11] [     6] D_mmd2 4.4675e+00 G_mmd2 4.5475e+00 mmd2_real 7.7431e-01 real_L2 0.268523 fake_L2 0.116267\n",
      "[    7/  100] [    6/   11] [     7] D_mmd2 4.5477e+00 G_mmd2 4.5831e+00 mmd2_real 7.4282e-01 real_L2 0.273850 fake_L2 0.113549\n",
      "[    8/  100] [    6/   11] [     8] D_mmd2 4.7803e+00 G_mmd2 4.7788e+00 mmd2_real 7.1175e-01 real_L2 0.284157 fake_L2 0.117586\n",
      "[    9/  100] [    6/   11] [     9] D_mmd2 4.7930e+00 G_mmd2 4.6015e+00 mmd2_real 7.4493e-01 real_L2 0.269103 fake_L2 0.105313\n",
      "[   10/  100] [    6/   11] [    10] D_mmd2 4.8269e+00 G_mmd2 4.9222e+00 mmd2_real 8.8985e-01 real_L2 0.276969 fake_L2 0.105681\n",
      "[   11/  100] [    6/   11] [    11] D_mmd2 4.9334e+00 G_mmd2 4.9212e+00 mmd2_real 7.2567e-01 real_L2 0.283319 fake_L2 0.102867\n",
      "[   12/  100] [    6/   11] [    12] D_mmd2 5.0551e+00 G_mmd2 4.9482e+00 mmd2_real 7.7793e-01 real_L2 0.261556 fake_L2 0.096381\n",
      "[   13/  100] [    6/   11] [    13] D_mmd2 4.9291e+00 G_mmd2 5.0245e+00 mmd2_real 6.8720e-01 real_L2 0.273233 fake_L2 0.093545\n",
      "[   14/  100] [    6/   11] [    14] D_mmd2 5.0598e+00 G_mmd2 5.0931e+00 mmd2_real 8.3120e-01 real_L2 0.252834 fake_L2 0.093863\n",
      "[   15/  100] [    6/   11] [    15] D_mmd2 5.1941e+00 G_mmd2 5.1402e+00 mmd2_real 6.7611e-01 real_L2 0.280743 fake_L2 0.086552\n",
      "[   16/  100] [    6/   11] [    16] D_mmd2 5.1570e+00 G_mmd2 5.1415e+00 mmd2_real 7.2924e-01 real_L2 0.264198 fake_L2 0.085606\n",
      "[   17/  100] [    6/   11] [    17] D_mmd2 5.2450e+00 G_mmd2 5.1655e+00 mmd2_real 7.2639e-01 real_L2 0.287405 fake_L2 0.087353\n",
      "[   18/  100] [    6/   11] [    18] D_mmd2 5.2917e+00 G_mmd2 5.2300e+00 mmd2_real 7.9126e-01 real_L2 0.265287 fake_L2 0.083272\n",
      "[   19/  100] [    6/   11] [    19] D_mmd2 5.3895e+00 G_mmd2 5.3995e+00 mmd2_real 6.6650e-01 real_L2 0.283487 fake_L2 0.084477\n",
      "[   20/  100] [    6/   11] [    20] D_mmd2 5.3050e+00 G_mmd2 5.2784e+00 mmd2_real 7.0976e-01 real_L2 0.244900 fake_L2 0.073893\n",
      "[   21/  100] [    6/   11] [    21] D_mmd2 5.3357e+00 G_mmd2 5.2597e+00 mmd2_real 6.7456e-01 real_L2 0.244387 fake_L2 0.072678\n",
      "[   22/  100] [    6/   11] [    22] D_mmd2 5.2507e+00 G_mmd2 5.4168e+00 mmd2_real 6.5896e-01 real_L2 0.265039 fake_L2 0.070099\n",
      "[   23/  100] [    6/   11] [    23] D_mmd2 5.4400e+00 G_mmd2 5.4111e+00 mmd2_real 6.2715e-01 real_L2 0.280567 fake_L2 0.077551\n",
      "[   24/  100] [    6/   11] [    24] D_mmd2 5.3746e+00 G_mmd2 5.3980e+00 mmd2_real 5.2542e-01 real_L2 0.259913 fake_L2 0.069482\n",
      "[   25/  100] [    6/   11] [    25] D_mmd2 5.5433e+00 G_mmd2 5.4634e+00 mmd2_real 5.7953e-01 real_L2 0.284674 fake_L2 0.071981\n",
      "[   26/  100] [    6/   11] [    26] D_mmd2 5.5125e+00 G_mmd2 5.4666e+00 mmd2_real 7.4985e-01 real_L2 0.234837 fake_L2 0.064845\n",
      "[   27/  100] [    6/   11] [    27] D_mmd2 5.4361e+00 G_mmd2 5.5407e+00 mmd2_real 6.4644e-01 real_L2 0.254396 fake_L2 0.062580\n",
      "[   28/  100] [    6/   11] [    28] D_mmd2 5.4769e+00 G_mmd2 5.4909e+00 mmd2_real 5.4439e-01 real_L2 0.246646 fake_L2 0.063192\n",
      "[   29/  100] [    6/   11] [    29] D_mmd2 5.5317e+00 G_mmd2 5.4994e+00 mmd2_real 6.4801e-01 real_L2 0.247457 fake_L2 0.067892\n",
      "[   30/  100] [    6/   11] [    30] D_mmd2 5.5009e+00 G_mmd2 5.5933e+00 mmd2_real 6.1237e-01 real_L2 0.231138 fake_L2 0.056778\n",
      "[   31/  100] [    6/   11] [    31] D_mmd2 5.5520e+00 G_mmd2 5.5060e+00 mmd2_real 5.6604e-01 real_L2 0.247182 fake_L2 0.058290\n",
      "[   32/  100] [    6/   11] [    32] D_mmd2 5.5160e+00 G_mmd2 5.5806e+00 mmd2_real 6.2261e-01 real_L2 0.230009 fake_L2 0.053417\n",
      "[   33/  100] [    6/   11] [    33] D_mmd2 5.6657e+00 G_mmd2 5.6168e+00 mmd2_real 6.7795e-01 real_L2 0.223876 fake_L2 0.057260\n",
      "[   34/  100] [    6/   11] [    34] D_mmd2 5.6447e+00 G_mmd2 5.5638e+00 mmd2_real 5.2147e-01 real_L2 0.222558 fake_L2 0.056575\n",
      "[   35/  100] [    6/   11] [    35] D_mmd2 5.6033e+00 G_mmd2 5.5400e+00 mmd2_real 7.3158e-01 real_L2 0.217209 fake_L2 0.053505\n",
      "[   36/  100] [    6/   11] [    36] D_mmd2 5.6114e+00 G_mmd2 5.6472e+00 mmd2_real 6.9995e-01 real_L2 0.227433 fake_L2 0.054238\n",
      "[   37/  100] [    6/   11] [    37] D_mmd2 5.7025e+00 G_mmd2 5.6611e+00 mmd2_real 5.3886e-01 real_L2 0.214931 fake_L2 0.053786\n",
      "[   38/  100] [    6/   11] [    38] D_mmd2 5.5637e+00 G_mmd2 5.7016e+00 mmd2_real 6.0733e-01 real_L2 0.214859 fake_L2 0.048706\n",
      "[   39/  100] [    6/   11] [    39] D_mmd2 5.8069e+00 G_mmd2 5.7794e+00 mmd2_real 5.7491e-01 real_L2 0.210188 fake_L2 0.047926\n",
      "[   40/  100] [    6/   11] [    40] D_mmd2 5.6093e+00 G_mmd2 5.7474e+00 mmd2_real 7.1657e-01 real_L2 0.207376 fake_L2 0.049634\n",
      "[   41/  100] [    6/   11] [    41] D_mmd2 5.8822e+00 G_mmd2 5.6779e+00 mmd2_real 5.9513e-01 real_L2 0.210728 fake_L2 0.048131\n",
      "[   42/  100] [    6/   11] [    42] D_mmd2 5.7065e+00 G_mmd2 5.7363e+00 mmd2_real 4.2608e-01 real_L2 0.222046 fake_L2 0.046727\n",
      "[   43/  100] [    6/   11] [    43] D_mmd2 5.7407e+00 G_mmd2 5.7371e+00 mmd2_real 6.1567e-01 real_L2 0.214749 fake_L2 0.040206\n",
      "[   44/  100] [    6/   11] [    44] D_mmd2 5.7724e+00 G_mmd2 5.7073e+00 mmd2_real 6.7182e-01 real_L2 0.197057 fake_L2 0.043955\n",
      "[   45/  100] [    6/   11] [    45] D_mmd2 5.7842e+00 G_mmd2 5.8326e+00 mmd2_real 5.7420e-01 real_L2 0.197134 fake_L2 0.042199\n",
      "[   46/  100] [    6/   11] [    46] D_mmd2 5.6631e+00 G_mmd2 5.6820e+00 mmd2_real 6.3408e-01 real_L2 0.186306 fake_L2 0.041169\n",
      "[   47/  100] [    6/   11] [    47] D_mmd2 5.5895e+00 G_mmd2 5.9375e+00 mmd2_real 5.9594e-01 real_L2 0.176688 fake_L2 0.041263\n",
      "[   48/  100] [    6/   11] [    48] D_mmd2 5.8746e+00 G_mmd2 5.8011e+00 mmd2_real 7.1773e-01 real_L2 0.190503 fake_L2 0.042994\n",
      "[   49/  100] [    6/   11] [    49] D_mmd2 5.7145e+00 G_mmd2 5.9367e+00 mmd2_real 6.0846e-01 real_L2 0.181079 fake_L2 0.040580\n",
      "[   50/  100] [    6/   11] [    50] D_mmd2 5.7752e+00 G_mmd2 5.8932e+00 mmd2_real 8.2193e-01 real_L2 0.167296 fake_L2 0.042413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eromanenkova/Intern_CPD/Alex/new_code/klcpd_code/mmd_util.py:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  sigma_samples = F.softmax(U * gumbel_lmd).matmul(sigma_var)\n",
      "/home/eromanenkova/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:32: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/eromanenkova/Intern_CPD/Alex/new_code/klcpd_code/mmd_util.py:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  sigma_samples = F.softmax(U * gumbel_lmd).matmul(sigma_var)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter   50 tm 10.19m val_mse -1.0 val_mae -1.0 val_auc 0.557692 tst_mse -1.0 tst_mae -1.0 tst_auc 0.463636 [best_val_auc 0.557692 best_tst_auc 0.463636 best_epoch  50]\n",
      "[   51/  100] [    6/   11] [    51] D_mmd2 5.7565e+00 G_mmd2 5.8559e+00 mmd2_real 6.8705e-01 real_L2 0.172274 fake_L2 0.038226\n",
      "[   52/  100] [    6/   11] [    52] D_mmd2 5.7777e+00 G_mmd2 5.7673e+00 mmd2_real 6.0610e-01 real_L2 0.169621 fake_L2 0.039980\n",
      "[   53/  100] [    6/   11] [    53] D_mmd2 5.8289e+00 G_mmd2 5.7512e+00 mmd2_real 6.9237e-01 real_L2 0.161879 fake_L2 0.036902\n",
      "[   54/  100] [    6/   11] [    54] D_mmd2 5.7577e+00 G_mmd2 5.7671e+00 mmd2_real 7.3265e-01 real_L2 0.162559 fake_L2 0.033637\n",
      "[   55/  100] [    6/   11] [    55] D_mmd2 5.9070e+00 G_mmd2 5.8920e+00 mmd2_real 7.8208e-01 real_L2 0.161554 fake_L2 0.034705\n",
      "[   56/  100] [    6/   11] [    56] D_mmd2 5.8005e+00 G_mmd2 5.8301e+00 mmd2_real 6.8453e-01 real_L2 0.144357 fake_L2 0.036829\n",
      "[   57/  100] [    6/   11] [    57] D_mmd2 5.9469e+00 G_mmd2 5.8216e+00 mmd2_real 6.0010e-01 real_L2 0.157660 fake_L2 0.035004\n",
      "[   58/  100] [    6/   11] [    58] D_mmd2 5.7035e+00 G_mmd2 5.9483e+00 mmd2_real 7.5528e-01 real_L2 0.150691 fake_L2 0.037825\n",
      "[   59/  100] [    6/   11] [    59] D_mmd2 5.7803e+00 G_mmd2 5.7914e+00 mmd2_real 6.4035e-01 real_L2 0.150409 fake_L2 0.033923\n",
      "[   60/  100] [    6/   11] [    60] D_mmd2 5.7766e+00 G_mmd2 5.8854e+00 mmd2_real 5.8438e-01 real_L2 0.150722 fake_L2 0.039144\n",
      "[   61/  100] [    6/   11] [    61] D_mmd2 5.9121e+00 G_mmd2 5.7219e+00 mmd2_real 7.2566e-01 real_L2 0.133409 fake_L2 0.037111\n",
      "[   62/  100] [    6/   11] [    62] D_mmd2 5.7824e+00 G_mmd2 5.6802e+00 mmd2_real 7.8820e-01 real_L2 0.139614 fake_L2 0.031709\n",
      "[   63/  100] [    6/   11] [    63] D_mmd2 5.7798e+00 G_mmd2 5.7427e+00 mmd2_real 7.5275e-01 real_L2 0.133272 fake_L2 0.029322\n",
      "[   64/  100] [    6/   11] [    64] D_mmd2 5.7333e+00 G_mmd2 5.8746e+00 mmd2_real 8.9135e-01 real_L2 0.120263 fake_L2 0.032102\n",
      "[   65/  100] [    6/   11] [    65] D_mmd2 5.6627e+00 G_mmd2 5.7545e+00 mmd2_real 7.2405e-01 real_L2 0.121256 fake_L2 0.027510\n",
      "[   66/  100] [    6/   11] [    66] D_mmd2 5.6408e+00 G_mmd2 5.7174e+00 mmd2_real 3.9966e-01 real_L2 0.127491 fake_L2 0.030088\n",
      "[   67/  100] [    6/   11] [    67] D_mmd2 5.8986e+00 G_mmd2 5.7688e+00 mmd2_real 5.0172e-01 real_L2 0.117358 fake_L2 0.032875\n",
      "[   68/  100] [    6/   11] [    68] D_mmd2 5.6740e+00 G_mmd2 5.7826e+00 mmd2_real 6.6297e-01 real_L2 0.127184 fake_L2 0.035401\n",
      "[   69/  100] [    6/   11] [    69] D_mmd2 5.7101e+00 G_mmd2 5.7772e+00 mmd2_real 7.4865e-01 real_L2 0.116919 fake_L2 0.032046\n",
      "[   70/  100] [    6/   11] [    70] D_mmd2 5.8749e+00 G_mmd2 5.8791e+00 mmd2_real 6.5751e-01 real_L2 0.121002 fake_L2 0.026804\n",
      "[   71/  100] [    6/   11] [    71] D_mmd2 5.6726e+00 G_mmd2 5.8200e+00 mmd2_real 6.7743e-01 real_L2 0.113061 fake_L2 0.028129\n",
      "[   72/  100] [    6/   11] [    72] D_mmd2 5.9942e+00 G_mmd2 5.8113e+00 mmd2_real 8.0089e-01 real_L2 0.106134 fake_L2 0.027050\n",
      "[   73/  100] [    6/   11] [    73] D_mmd2 5.7257e+00 G_mmd2 5.7805e+00 mmd2_real 6.7909e-01 real_L2 0.113168 fake_L2 0.032440\n",
      "[   74/  100] [    6/   11] [    74] D_mmd2 5.8062e+00 G_mmd2 5.6782e+00 mmd2_real 5.7792e-01 real_L2 0.107808 fake_L2 0.031301\n",
      "[   75/  100] [    6/   11] [    75] D_mmd2 5.7419e+00 G_mmd2 5.7340e+00 mmd2_real 7.3384e-01 real_L2 0.105092 fake_L2 0.030810\n",
      "[   76/  100] [    6/   11] [    76] D_mmd2 5.7035e+00 G_mmd2 5.9039e+00 mmd2_real 5.0540e-01 real_L2 0.103080 fake_L2 0.034022\n",
      "[   77/  100] [    6/   11] [    77] D_mmd2 5.8700e+00 G_mmd2 5.7418e+00 mmd2_real 6.8894e-01 real_L2 0.108160 fake_L2 0.027893\n",
      "[   78/  100] [    6/   11] [    78] D_mmd2 5.5371e+00 G_mmd2 5.7477e+00 mmd2_real 8.6069e-01 real_L2 0.098708 fake_L2 0.028196\n",
      "[   79/  100] [    6/   11] [    79] D_mmd2 5.7517e+00 G_mmd2 5.7932e+00 mmd2_real 6.7604e-01 real_L2 0.103512 fake_L2 0.028053\n",
      "[   80/  100] [    6/   11] [    80] D_mmd2 5.6980e+00 G_mmd2 5.6987e+00 mmd2_real 7.3591e-01 real_L2 0.089719 fake_L2 0.028460\n",
      "[   81/  100] [    6/   11] [    81] D_mmd2 5.8919e+00 G_mmd2 5.7072e+00 mmd2_real 8.5362e-01 real_L2 0.096032 fake_L2 0.032726\n",
      "[   82/  100] [    6/   11] [    82] D_mmd2 5.7976e+00 G_mmd2 5.7466e+00 mmd2_real 6.2596e-01 real_L2 0.093151 fake_L2 0.028330\n",
      "[   83/  100] [    6/   11] [    83] D_mmd2 5.6275e+00 G_mmd2 5.7453e+00 mmd2_real 9.6540e-01 real_L2 0.084158 fake_L2 0.026642\n",
      "[   84/  100] [    6/   11] [    84] D_mmd2 5.6550e+00 G_mmd2 5.7190e+00 mmd2_real 7.5192e-01 real_L2 0.090819 fake_L2 0.030896\n",
      "[   85/  100] [    6/   11] [    85] D_mmd2 5.5116e+00 G_mmd2 5.7932e+00 mmd2_real 9.5273e-01 real_L2 0.084148 fake_L2 0.028156\n",
      "[   86/  100] [    6/   11] [    86] D_mmd2 5.5728e+00 G_mmd2 5.6448e+00 mmd2_real 6.3609e-01 real_L2 0.085283 fake_L2 0.031090\n",
      "[   87/  100] [    6/   11] [    87] D_mmd2 5.6631e+00 G_mmd2 5.3908e+00 mmd2_real 6.5427e-01 real_L2 0.081956 fake_L2 0.027124\n",
      "[   88/  100] [    6/   11] [    88] D_mmd2 5.6272e+00 G_mmd2 5.7142e+00 mmd2_real 7.9259e-01 real_L2 0.086907 fake_L2 0.030496\n",
      "[   89/  100] [    6/   11] [    89] D_mmd2 5.6392e+00 G_mmd2 5.6106e+00 mmd2_real 6.6337e-01 real_L2 0.073791 fake_L2 0.023760\n",
      "[   90/  100] [    6/   11] [    90] D_mmd2 5.7123e+00 G_mmd2 5.6175e+00 mmd2_real 7.9024e-01 real_L2 0.080613 fake_L2 0.023372\n",
      "[   91/  100] [    6/   11] [    91] D_mmd2 5.8757e+00 G_mmd2 5.7432e+00 mmd2_real 6.7457e-01 real_L2 0.083159 fake_L2 0.027133\n",
      "[   92/  100] [    6/   11] [    92] D_mmd2 5.6524e+00 G_mmd2 5.5539e+00 mmd2_real 5.7278e-01 real_L2 0.076545 fake_L2 0.028077\n",
      "[   93/  100] [    6/   11] [    93] D_mmd2 5.4429e+00 G_mmd2 5.7173e+00 mmd2_real 9.4334e-01 real_L2 0.070758 fake_L2 0.025621\n",
      "[   94/  100] [    6/   11] [    94] D_mmd2 5.4083e+00 G_mmd2 5.7959e+00 mmd2_real 7.0790e-01 real_L2 0.078091 fake_L2 0.029095\n",
      "[   95/  100] [    6/   11] [    95] D_mmd2 5.7967e+00 G_mmd2 5.6107e+00 mmd2_real 6.8949e-01 real_L2 0.072057 fake_L2 0.027345\n",
      "[   96/  100] [    6/   11] [    96] D_mmd2 5.6495e+00 G_mmd2 5.4181e+00 mmd2_real 4.8559e-01 real_L2 0.071683 fake_L2 0.028607\n",
      "[   97/  100] [    6/   11] [    97] D_mmd2 5.5093e+00 G_mmd2 5.5546e+00 mmd2_real 7.9076e-01 real_L2 0.069354 fake_L2 0.022297\n",
      "[   98/  100] [    6/   11] [    98] D_mmd2 5.6009e+00 G_mmd2 5.6191e+00 mmd2_real 7.2200e-01 real_L2 0.067955 fake_L2 0.024531\n",
      "[   99/  100] [    6/   11] [    99] D_mmd2 5.5063e+00 G_mmd2 5.5456e+00 mmd2_real 8.5204e-01 real_L2 0.066879 fake_L2 0.028880\n",
      "[  100/  100] [    6/   11] [   100] D_mmd2 5.8124e+00 G_mmd2 5.4827e+00 mmd2_real 6.8655e-01 real_L2 0.065138 fake_L2 0.027404\n",
      "iter  100 tm 10.32m val_mse -1.0 val_mae -1.0 val_auc 0.531674 tst_mse -1.0 tst_mae -1.0 tst_auc 0.480682 [best_val_auc 0.531674 best_tst_auc 0.480682 best_epoch 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eromanenkova/Intern_CPD/Alex/new_code/klcpd_code/mmd_util.py:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  sigma_samples = F.softmax(U * gumbel_lmd).matmul(sigma_var)\n",
      "/home/eromanenkova/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:32: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/eromanenkova/Intern_CPD/Alex/new_code/klcpd_code/mmd_util.py:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  sigma_samples = F.softmax(U * gumbel_lmd).matmul(sigma_var)\n"
     ]
    }
   ],
   "source": [
    "print('start training: lambda_ae', lambda_ae, 'lambda_real', lambda_real, 'weight_clip', args['weight_clip'])\n",
    "\n",
    "for epoch in range(1, args['max_iter'] + 1):\n",
    "#while(best_mmd_real > 1e-4):\n",
    "    trn_loader = Data.get_batches(Data.trn_set, batch_size=args['batch_size'], shuffle=True)\n",
    "    bidx = 0\n",
    "    while bidx < n_batchs:\n",
    "        ############################\n",
    "        # (1) Update D network\n",
    "        ############################\n",
    "        for p in netD.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "        for diters in range(args['CRITIC_ITERS']):\n",
    "            # clamp parameters of NetD encoder to a cube\n",
    "            for p in netD.rnn_enc_layer.parameters():\n",
    "                p.data.clamp_(-args['weight_clip'], args['weight_clip'])\n",
    "            if bidx == n_batchs:\n",
    "                break\n",
    "\n",
    "            inputs = next(trn_loader)\n",
    "            X_p, X_f, Y_true = inputs[0], inputs[1], inputs[2]\n",
    "            batch_size = X_p.size(0)\n",
    "            bidx += 1\n",
    "\n",
    "            # real data\n",
    "            X_p_enc, X_p_dec = netD(X_p)\n",
    "            X_f_enc, X_f_dec = netD(X_f)\n",
    "\n",
    "            # fake data\n",
    "            noise = torch.cuda.FloatTensor(1, batch_size, args['RNN_hid_dim']).normal_(0, 1) # брал cuda\n",
    "            noise = Variable(noise, volatile=True) # total freeze netG\n",
    "            Y_f = Variable(netG(X_p, X_f, noise).data)\n",
    "            Y_f_enc, Y_f_dec = netD(Y_f)\n",
    "\n",
    "            # batchwise MMD2 loss between X_f and Y_f\n",
    "            D_mmd2 = mmd_util.batch_mmd2_loss(X_f_enc, Y_f_enc, sigma_var)\n",
    "\n",
    "            # batchwise MMD2 loss between X_f and Y_f\n",
    "            mmd2_real = mmd_util.batch_mmd2_loss(X_p_enc, X_f_enc, sigma_var)\n",
    "\n",
    "            # reconstruction loss\n",
    "            real_L2_loss = torch.mean((X_f - X_f_dec)**2)\n",
    "            #real_L2_loss = torch.mean((X_p - X_p_dec)**2)\n",
    "            fake_L2_loss = torch.mean((Y_f - Y_f_dec)**2)\n",
    "            #fake_L2_loss = torch.mean((Y_f - Y_f_dec)**2) * 0.0\n",
    "\n",
    "            # update netD\n",
    "            netD.zero_grad()\n",
    "            lossD = D_mmd2.mean() - lambda_ae * (real_L2_loss + fake_L2_loss) - lambda_real * mmd2_real.mean()\n",
    "            #lossD = 0.0 * D_mmd2.mean() - lambda_ae * (real_L2_loss + fake_L2_loss) - lambda_real * mmd2_real.mean()\n",
    "            #lossD = -real_L2_loss\n",
    "            lossD.backward(mone)\n",
    "            optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network\n",
    "        ############################\n",
    "        for p in netD.parameters():\n",
    "            p.requires_grad = False  # to avoid computation\n",
    "\n",
    "        if bidx == n_batchs:\n",
    "            break\n",
    "\n",
    "        inputs = next(trn_loader)\n",
    "        X_p, X_f = inputs[0], inputs[1]\n",
    "        batch_size = X_p.size(0)\n",
    "        bidx += 1\n",
    "\n",
    "        # real data\n",
    "        X_f_enc, X_f_dec = netD(X_f)\n",
    "\n",
    "        # fake data\n",
    "        noise = torch.cuda.FloatTensor(1, batch_size, args['RNN_hid_dim']).normal_(0, 1) # убрал cuda\n",
    "        noise = Variable(noise)\n",
    "        Y_f = netG(X_p, X_f, noise)\n",
    "        Y_f_enc, Y_f_dec = netD(Y_f)\n",
    "\n",
    "        # batchwise MMD2 loss between X_f and Y_f\n",
    "        G_mmd2 = mmd_util.batch_mmd2_loss(X_f_enc, Y_f_enc, sigma_var)\n",
    "\n",
    "        # update netG\n",
    "        netG.zero_grad()\n",
    "        lossG = G_mmd2.mean()\n",
    "        #lossG = 0.0 * G_mmd2.mean()\n",
    "        lossG.backward(one)\n",
    "        optimizerG.step()\n",
    "\n",
    "        #G_mmd2 = Variable(torch.FloatTensor(batch_size).zero_())\n",
    "        gen_iterations += 1\n",
    "\n",
    "        #print('D_mmd2:', D_mmd2.mean().item())\n",
    "\n",
    "        print('[%5d/%5d] [%5d/%5d] [%6d] D_mmd2 %.4e G_mmd2 %.4e mmd2_real %.4e real_L2 %.6f fake_L2 %.6f'\n",
    "              % (epoch, args['max_iter'], bidx, n_batchs, gen_iterations,\n",
    "                 D_mmd2.mean().item(), G_mmd2.mean().item(), mmd2_real.mean().item(),\n",
    "                 real_L2_loss.item(), fake_L2_loss.item()))\n",
    "\n",
    "        if gen_iterations % args['eval_freq'] == 0:\n",
    "            # ========= Main block for evaluate MMD(X_p_enc, X_f_enc) on RNN codespace  =========#\n",
    "            val_dict = valid_epoch(Data, Data.val_set, netD, args['batch_size'], Y_val, L_val)\n",
    "            tst_dict = valid_epoch(Data, Data.tst_set, netD, args['batch_size'], Y_tst, L_tst)\n",
    "            total_time = time.time() - start_time\n",
    "            print('iter %4d tm %4.2fm val_mse %.1f val_mae %.1f val_auc %.6f'\n",
    "                    % (epoch, total_time / 60.0, val_dict['mse'], val_dict['mae'], val_dict['auc']), end='')\n",
    "\n",
    "            print (\" tst_mse %.1f tst_mae %.1f tst_auc %.6f\" % (tst_dict['mse'], tst_dict['mae'], tst_dict['auc']), end='')\n",
    "\n",
    "            assert(np.isnan(val_dict['auc']) != True)\n",
    "            #if val_dict['auc'] > best_val_auc:\n",
    "            #if val_dict['auc'] > best_val_auc and mmd2_real.mean().data[0] < best_mmd_real:\n",
    "            if mmd2_real.mean().item() < best_mmd_real:\n",
    "                best_mmd_real = mmd2_real.mean().item()\n",
    "                best_val_mae = val_dict['mae']\n",
    "                best_val_auc = val_dict['auc']\n",
    "                best_tst_auc = tst_dict['auc']\n",
    "                best_epoch = epoch\n",
    "                save_pred_name = '%s/pred.pkl' % (args['save_path'])\n",
    "                with open(save_pred_name, 'wb') as f:\n",
    "                    pickle.dump(tst_dict, f)\n",
    "                torch.save(netG.state_dict(), '%s/netG.pkl' % (args['save_path']))\n",
    "                torch.save(netD.state_dict(), '%s/netD.pkl' % (args['save_path']))\n",
    "            print(\" [best_val_auc %.6f best_tst_auc %.6f best_epoch %3d]\" % (best_val_auc, best_tst_auc, best_epoch))\n",
    "\n",
    "        # stopping condition\n",
    "        #if best_mmd_real < 1e-4:\n",
    "        #if mmd2_real.mean().item() < 1e-5:\n",
    "        #    exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2b9e5a",
   "metadata": {},
   "source": [
    "## Try evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e764a0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y, L should be numpy array\n",
    "'''\n",
    "def valid_epoch(loader, data, netD, batch_size, Y_true, L_true):\n",
    "    netD.eval()\n",
    "    Y_pred = []\n",
    "    for inputs in loader.get_batches(data, batch_size, shuffle=False):\n",
    "        X_p, X_f = inputs[0], inputs[1]\n",
    "        batch_size = X_p.size(0)\n",
    "\n",
    "        X_p_enc, _ = netD(X_p)\n",
    "        X_f_enc, _ = netD(X_f)\n",
    "        Y_pred_batch = mmd_util.batch_mmd2_loss(X_p_enc, X_f_enc, sigma_var)\n",
    "        Y_pred.append(Y_pred_batch.data.cpu().numpy())\n",
    "    Y_pred = np.concatenate(Y_pred, axis=0)\n",
    "\n",
    "    L_pred = Y_pred\n",
    "    fp_list, tp_list, thresholds = sklearn.metrics.roc_curve(L_true, L_pred)\n",
    "    auc = sklearn.metrics.auc(fp_list, tp_list)\n",
    "    eval_dict = {'Y_pred': Y_pred,\n",
    "                 'L_pred': L_pred,\n",
    "                 'Y_true': Y_true,\n",
    "                 'L_true': L_true,\n",
    "                 'mse': -1, 'mae': -1, 'auc': auc}\n",
    "    netD.train()\n",
    "    return eval_dict\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31345840",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_dict = valid_epoch(Data, Data.tst_set, netD, args['batch_size'], Y_tst, L_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e578bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tst_dict['Y_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa9f9dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.3198833 , 0.9263717 , 0.9550988 , 1.2123823 , 0.70658636,\n",
       "       0.8189267 , 0.6951982 , 0.59443116, 0.7179463 , 0.576398  ,\n",
       "       0.7867337 , 0.81778646, 0.6987508 , 0.5895537 , 0.8825915 ,\n",
       "       0.5416032 , 0.5967457 , 0.85930073, 0.6648186 , 0.7869399 ,\n",
       "       0.8073334 , 1.3046923 , 1.0588747 , 0.96216416, 0.6746737 ,\n",
       "       0.92985415, 0.936676  , 0.9073333 , 1.1053972 , 0.8175859 ,\n",
       "       1.1539639 , 1.0403857 , 1.4272169 , 1.1721958 , 1.4914905 ,\n",
       "       1.1718202 , 1.239691  , 1.4163982 , 1.5531106 , 1.732186  ,\n",
       "       1.5711713 , 1.6407499 , 1.7064996 , 1.623909  , 1.1503116 ,\n",
       "       1.1967565 , 1.388103  , 1.48285   , 1.4674764 , 1.0193081 ,\n",
       "       0.73134327, 0.64401203, 0.5747048 , 0.56050277, 0.4581817 ,\n",
       "       0.32509428, 0.21283194, 0.14070709, 0.14137138, 0.16090584,\n",
       "       0.1608504 , 0.19873562, 0.25129342, 0.32127962, 0.43185693,\n",
       "       0.53310513, 0.6186771 , 0.5723858 , 0.70420706, 0.91390157,\n",
       "       1.2645519 , 1.5048811 , 1.8056793 , 2.052476  , 2.1547043 ,\n",
       "       2.1973174 , 2.287465  , 2.344944  , 2.1108475 , 2.0690176 ,\n",
       "       2.1283848 , 1.9716902 , 1.8664938 , 1.9680414 , 2.1601129 ,\n",
       "       2.4560273 , 2.4956348 , 2.6176958 , 2.6012073 , 2.469553  ,\n",
       "       2.3615701 , 2.0050688 , 1.7695087 , 1.5405979 , 1.3314507 ,\n",
       "       1.0606344 , 0.7446451 , 0.63060063, 0.51109886, 0.44242585,\n",
       "       0.23687962, 0.21915746, 0.07929197, 0.04401371, 0.04708889,\n",
       "       0.03006781, 0.08933076, 0.05883341, 0.11660407, 0.22534992,\n",
       "       0.22059827, 0.3267144 , 0.18770097, 0.23147672, 0.35930803,\n",
       "       0.4639691 , 0.61991775, 0.56686676, 0.5115318 , 0.43548524,\n",
       "       0.51503587, 0.5059242 , 0.49652156, 0.5265924 , 0.40224952,\n",
       "       0.35640016, 0.4467869 , 0.50330806, 0.55116993, 0.580421  ,\n",
       "       0.5419274 , 0.44397524, 0.3638256 , 0.28733975, 0.33849603,\n",
       "       0.32289216, 0.1953119 , 0.10144197, 0.05315243, 0.03951725,\n",
       "       0.02110377, 0.01824397, 0.02429694, 0.0198196 , 0.04917335,\n",
       "       0.06637348, 0.05308655, 0.05403075, 0.05660904, 0.05356899,\n",
       "       0.03834497, 0.02336528, 0.02286455, 0.02694808, 0.03626184,\n",
       "       0.0456068 , 0.0840979 , 0.1425505 , 0.27232236, 0.47827142,\n",
       "       0.7183469 , 1.1321691 , 1.5688171 , 1.9208206 , 2.1303425 ,\n",
       "       1.9883314 , 2.1802297 , 2.1531532 , 2.3014617 , 2.048604  ,\n",
       "       2.0679762 , 2.2243361 , 2.2877097 , 2.5210798 , 2.6632059 ,\n",
       "       2.5074744 , 2.5523982 , 2.1490364 , 2.0344486 , 2.2763433 ,\n",
       "       2.2093134 , 2.0270243 , 2.001548  , 1.9794763 , 2.125376  ,\n",
       "       2.2047532 , 2.3763313 , 2.3838305 , 2.6050038 , 2.7942247 ,\n",
       "       2.5903702 , 2.291534  , 2.2762456 , 2.021742  , 1.8660533 ,\n",
       "       1.5461252 , 1.3837675 , 1.1625395 , 0.9460064 , 0.77576977,\n",
       "       0.5790543 , 0.4295777 , 0.3603859 , 0.22934592, 0.10409907,\n",
       "       0.07588926, 0.07385181, 0.0632691 , 0.09287783, 0.275246  ,\n",
       "       0.21432482, 0.33345923, 0.42016017, 0.396595  , 0.797645  ,\n",
       "       0.74581134, 0.9680086 , 0.63374984, 0.6584594 , 0.66383374,\n",
       "       0.5005573 , 0.48419723, 0.53739977, 0.26391128], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b03c12c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.tst_set['Y'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea719648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa55795f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7afd9135",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tst_dict['L_pred'].flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8c47007",
   "metadata": {},
   "outputs": [],
   "source": [
    "true = L_tst.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "386c4f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de5afafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f019d2b8850>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(pred, label='pred')\n",
    "plt.plot(true, label='true')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d096c8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 42,  86, 145, 206]),)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_indexes = np.where(L_tst.flatten() == 1)\n",
    "true_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1ca4fcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f426bda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 41,  77,  88, 173, 189])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_indexes = find_peaks(tst_dict['L_pred'].flatten(), height=1.25, distance=10)\n",
    "pred_indexes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa42dd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_list, tp_list, thresholds = sklearn.metrics.roc_curve(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731c669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cf87ee",
   "metadata": {},
   "source": [
    "## Converting our synthetic sequences into this format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3730cd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels2indexes(labels_seq):\n",
    "    cp_indexes = []\n",
    "    last_label_type = labels_seq[0]\n",
    "    for i in range(len(labels_seq) - 1):\n",
    "        if labels_seq[i+1] != last_label_type:\n",
    "            cp_indexes.append(i+1)\n",
    "            last_label_type = labels_seq[i+1]\n",
    "    \n",
    "    if not cp_indexes:\n",
    "        cp_indexes = [-1]\n",
    "    return cp_indexes\n",
    "\n",
    "def indexes2labels(cp_indexes, seq_len):\n",
    "    labels_seq = np.array([])\n",
    "    cp_indexes = cp_indexes + [seq_len]\n",
    "    start = 0\n",
    "    for i in range(len(cp_indexes)):\n",
    "        end = cp_indexes[i] - 1\n",
    "        segm_len = end - start + 1\n",
    "    \n",
    "        if i % 2 == 0:\n",
    "            labels_segm = np.zeros(segm_len)\n",
    "        else:\n",
    "            labels_segm = np.ones(segm_len)\n",
    "            \n",
    "        labels_seq = np.append(labels_seq, labels_segm)\n",
    "        start = end + 1\n",
    "    return labels_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d3cfd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CPD import datasets, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a7fc53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_1D = datasets.SyntheticNormalDataset(seq_len=128, num=300, D=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a98c52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_index = 0\n",
    "normal_index = 200\n",
    "\n",
    "abnormal_seq = test_dataset_1D.data[abnormal_index]\n",
    "abnormal_true_labels = test_dataset_1D.labels[abnormal_index]\n",
    "\n",
    "normal_seq = test_dataset_1D.data[normal_index]\n",
    "normal_true_labels = test_dataset_1D.labels[normal_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e5402e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abnormal_seq.numpy().shape # shape is ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb584460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abnormal_true_indexes = labels2indexes(abnormal_true_labels)\n",
    "new_abnormal_true_indexes = np.zeros(128)\n",
    "new_abnormal_true_indexes[abnormal_true_indexes] = 1.\n",
    "new_abnormal_true_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49988e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_abnormal_true_indexes = new_abnormal_true_indexes.reshape(128, 1)\n",
    "#new_abnormal_true_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ddeaee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_loaded_dataset = {}\n",
    "our_loaded_dataset['Y'] = abnormal_seq.numpy()\n",
    "our_loaded_dataset['L'] = new_abnormal_true_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c29dead",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurDataLoader(object):\n",
    "    def __init__(self, args, seq, labels, trn_ratio=0.6, val_ratio=0.8):\n",
    "        #self.cuda = args['cuda']\n",
    "        self.cuda = True\n",
    "        #self.data_path = args['data_path']\n",
    "        self.p_wnd_dim = 25\n",
    "        self.f_wnd_dim = args['wnd_dim']\n",
    "        self.sub_dim = args['sub_dim']\n",
    "        self.batch_size = args['batch_size']\n",
    "        self.Y = seq\n",
    "        self.L = labels\n",
    "\n",
    "        # load data\n",
    "        self.load_data(trn_ratio=trn_ratio, val_ratio=val_ratio)\n",
    "\n",
    "        # prepare data\n",
    "        self.prepare_data()\n",
    "\n",
    "        # split data into trn/val/tst set\n",
    "        self.split_data()\n",
    "\n",
    "    # load data\n",
    "    def load_data(self, trn_ratio=0.6, val_ratio=0.8):\n",
    "        '''\n",
    "        assert(os.path.lexists(self.data_path))\n",
    "        dataset = sio.loadmat(self.data_path)\n",
    "        self.Y = dataset['Y']                                   # Y: time series data, time length x number of variables\n",
    "        self.L = dataset['L']                                   # L: label of anomaly, time length x 1\n",
    "        self.T, self.D = self.Y.shape                           # T: time length; D: variable dimension\n",
    "        self.n_trn = int(np.ceil(self.T * trn_ratio))           # n_trn: first index of val set\n",
    "        self.n_val = int(np.ceil(self.T * val_ratio))           # n_val: first index of tst set\n",
    "        self.var_dim = self.D * self.sub_dim\n",
    "        \n",
    "        return dataset\n",
    "        '''\n",
    "        dataset = {}\n",
    "        dataset['Y'] = self.Y\n",
    "        dataset['L'] = self.L\n",
    "        self.T, self.D = self.Y.shape\n",
    "        self.n_trn = int(np.ceil(self.T * trn_ratio))           # n_trn: first index of val set\n",
    "        self.n_val = int(np.ceil(self.T * val_ratio))           # n_val: first index of tst set\n",
    "        self.var_dim = self.D * self.sub_dim\n",
    "        \n",
    "        return dataset\n",
    "\n",
    "    # prepare subspace data (Hankel matrix)\n",
    "    def prepare_data(self):\n",
    "        # T x D x sub_dim\n",
    "        self.Y_subspace = np.zeros((self.T, self.D, self.sub_dim))\n",
    "        for t in range(self.sub_dim, self.T):\n",
    "            for d in range(self.D):\n",
    "                self.Y_subspace[t, d, :] = self.Y[t - self.sub_dim + 1 : t + 1, d].flatten()\n",
    "\n",
    "        # Y_subspace is now T x (D x sub_dim)\n",
    "        self.Y_subspace = self.Y_subspace.reshape(self.T, -1)\n",
    "        \n",
    "        return self.Y_subspace\n",
    "\n",
    "    # split data into trn/val/tst set\n",
    "    def split_data(self):\n",
    "        trn_set_idx = range(self.p_wnd_dim, self.n_trn)\n",
    "        val_set_idx = range(self.n_trn, self.n_val)\n",
    "        tst_set_idx = range(self.n_val, self.T)\n",
    "        print('n_trn ', len(trn_set_idx), 'n_val ', len(val_set_idx), 'n_tst ', len(tst_set_idx))\n",
    "        self.trn_set = self.__batchify(trn_set_idx)\n",
    "        self.val_set = self.__batchify(val_set_idx)\n",
    "        self.tst_set = self.__batchify(tst_set_idx)\n",
    "        \n",
    "        return self.trn_set, self.tst_set, self.val_set\n",
    "\n",
    "    # convert augmented data in Hankel matrix to origin time series\n",
    "    # input: X_f, whose shape is batch_size x seq_len x (D*sub_dim)\n",
    "    # output: Y_t, whose shape is batch_size x D\n",
    "    def repack_data(self, X_f, batch_size):\n",
    "        Y_t = X_f[:, 0, :].contiguous().view(batch_size, self.D, self.sub_dim)\n",
    "        return Y_t[:, :, -1]\n",
    "\n",
    "    def __batchify(self, idx_set):\n",
    "        n = len(idx_set)\n",
    "        L = torch.zeros((n, 1))                             # anomaly label\n",
    "        Y = torch.zeros((n, self.D))                        # true signal\n",
    "        X_p = torch.zeros((n, self.p_wnd_dim, self.var_dim))  # past window buffer\n",
    "        X_f = torch.zeros((n, self.f_wnd_dim, self.var_dim))  # future window buffer\n",
    "\n",
    "        # XXX: dirty trick to augment the last buffer\n",
    "        data = np.concatenate((self.Y_subspace, self.Y_subspace[-self.f_wnd_dim:, :]))\n",
    "        for i in range(n):\n",
    "            l = idx_set[i] - self.p_wnd_dim\n",
    "            m = idx_set[i]\n",
    "            u = idx_set[i] + self.f_wnd_dim\n",
    "            X_p[i, :, :] = torch.from_numpy(data[l:m, :])\n",
    "            X_f[i, :, :] = torch.from_numpy(data[m:u, :])\n",
    "            Y[i, :] = torch.from_numpy(self.Y[m, :])\n",
    "            L[i] = torch.from_numpy(self.L[m])\n",
    "        return {'X_p': X_p, 'X_f': X_f, 'Y': Y, 'L': L}\n",
    "\n",
    "    def get_batches(self, data_set, batch_size, shuffle=False):\n",
    "        X_p, X_f = data_set['X_p'], data_set['X_f']\n",
    "        Y, L = data_set['Y'], data_set['L']\n",
    "        length = len(Y)\n",
    "        if shuffle:\n",
    "            index = torch.randperm(length)\n",
    "        else:\n",
    "            index = torch.LongTensor(range(length))\n",
    "        s_idx = 0\n",
    "        while (s_idx < length):\n",
    "            e_idx = min(length, s_idx + batch_size)\n",
    "            excerpt = index[s_idx:e_idx]\n",
    "            X_p_batch, X_f_batch = X_p[excerpt], X_f[excerpt]\n",
    "            Y_batch, L_batch = Y[excerpt], L[excerpt]\n",
    "            if self.cuda:\n",
    "                X_p_batch = X_p_batch.cuda()\n",
    "                X_f_batch = X_f_batch.cuda()\n",
    "                Y_batch = Y_batch.cuda()\n",
    "                L_batch = L_batch.cuda()\n",
    "\n",
    "            data = [Variable(X_p_batch),\n",
    "                    Variable(X_f_batch),\n",
    "                    Variable(Y_batch),\n",
    "                    Variable(L_batch)]\n",
    "            yield data\n",
    "            s_idx += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2820b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_trn  52 n_val  26 n_tst  25\n"
     ]
    }
   ],
   "source": [
    "our_1D_Data = OurDataLoader(seq=abnormal_seq.numpy(),\n",
    "                            labels=new_abnormal_true_indexes,\n",
    "                            args=args,\n",
    "                            trn_ratio=args['trn_ratio'],\n",
    "                            val_ratio=args['val_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f37a0501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52, 25, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_1D_Data.trn_set['X_p'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b153732d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52, 10, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_1D_Data.trn_set['X_f'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "608942f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = NetG(args, our_1D_Data)\n",
    "netD = NetD(args, our_1D_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6867b105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetG(\n",
      "  (rnn_enc_layer): GRU(1, 10, batch_first=True)\n",
      "  (rnn_dec_layer): GRU(1, 10, batch_first=True)\n",
      "  (fc_layer): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n",
      "NetD(\n",
      "  (rnn_enc_layer): GRU(1, 10, batch_first=True)\n",
      "  (rnn_dec_layer): GRU(10, 1, batch_first=True)\n",
      ")\n",
      "netG has number of parameters: 791\n",
      "netD has number of parameters: 429\n"
     ]
    }
   ],
   "source": [
    "if args['cuda']:\n",
    "    netG.cuda()\n",
    "    netD.cuda()\n",
    "    \n",
    "netG_params_count = sum([p.nelement() for p in netG.parameters()])\n",
    "netD_params_count = sum([p.nelement() for p in netD.parameters()])\n",
    "print(netG)\n",
    "print(netD)\n",
    "print('netG has number of parameters: %d' % (netG_params_count))\n",
    "print('netD has number of parameters: %d' % (netD_params_count))\n",
    "one = torch.tensor(1, dtype=torch.float)\n",
    "\n",
    "mone = one * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84ab6229",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerG = Optim(netG.parameters(),\n",
    "                   'adam',\n",
    "                   lr=3e-4,\n",
    "                   grad_clip=10.0,\n",
    "                   weight_decay=0.,\n",
    "                   momentum=0.0)\n",
    "\n",
    "optimizerD = Optim(netD.parameters(),\n",
    "                   'adam',\n",
    "                   lr=3e-4,\n",
    "                   grad_clip=10.0,\n",
    "                   weight_decay=0.,\n",
    "                   momentum=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e524234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma_list: tensor([ 1.4390,  2.8780,  5.7560, 11.5119, 23.0239], device='cuda:0')\n",
      "n_batchs 1 batch_size 128\n"
     ]
    }
   ],
   "source": [
    "sigma_list = mmd_util.median_heuristic(our_1D_Data.Y_subspace, beta=.5)\n",
    "sigma_var = torch.FloatTensor(sigma_list).cuda()\n",
    "print('sigma_list:', sigma_var)\n",
    "\n",
    "# ========= Main loop for adversarial training kernel with negative samples X_f + noise =========#\n",
    "Y_val = our_1D_Data.val_set['Y'].numpy()\n",
    "L_val = our_1D_Data.val_set['L'].numpy()\n",
    "Y_tst = our_1D_Data.tst_set['Y'].numpy()\n",
    "L_tst = our_1D_Data.tst_set['L'].numpy()\n",
    "\n",
    "n_batchs = int(math.ceil(len(our_1D_Data.trn_set['Y']) / float(args['batch_size'])))\n",
    "print('n_batchs', n_batchs, 'batch_size', args['batch_size'])\n",
    "\n",
    "lambda_ae = args['lambda_ae']\n",
    "lambda_real = args['lambda_real']\n",
    "gen_iterations = 0\n",
    "total_time = 0.\n",
    "best_epoch = -1\n",
    "best_val_mae = 1e+6\n",
    "best_val_auc = -1\n",
    "best_tst_auc = -1\n",
    "best_mmd_real = 1e+6\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9203f1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training: lambda_ae 0.001 lambda_real 0.1 weight_clip 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eromanenkova/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:32: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    }
   ],
   "source": [
    "print('start training: lambda_ae', lambda_ae, 'lambda_real', lambda_real, 'weight_clip', args['weight_clip'])\n",
    "\n",
    "for epoch in range(1, args['max_iter'] + 1):\n",
    "#while(best_mmd_real > 1e-4):\n",
    "    trn_loader = our_1D_Data.get_batches(our_1D_Data.trn_set, batch_size=args['batch_size'], shuffle=True)\n",
    "    bidx = 0\n",
    "    while bidx < n_batchs:\n",
    "        ############################\n",
    "        # (1) Update D network\n",
    "        ############################\n",
    "        for p in netD.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "        for diters in range(args['CRITIC_ITERS']):\n",
    "            # clamp parameters of NetD encoder to a cube\n",
    "            for p in netD.rnn_enc_layer.parameters():\n",
    "                p.data.clamp_(-args['weight_clip'], args['weight_clip'])\n",
    "            if bidx == n_batchs:\n",
    "                break\n",
    "\n",
    "            inputs = next(trn_loader)\n",
    "            X_p, X_f, Y_true = inputs[0], inputs[1], inputs[2]\n",
    "            batch_size = X_p.size(0)\n",
    "            bidx += 1\n",
    "\n",
    "            # real data\n",
    "            X_p_enc, X_p_dec = netD(X_p)\n",
    "            X_f_enc, X_f_dec = netD(X_f)\n",
    "\n",
    "            # fake data\n",
    "            noise = torch.cuda.FloatTensor(1, batch_size, args['RNN_hid_dim']).normal_(0, 1)\n",
    "            noise = Variable(noise, volatile=True) # total freeze netG\n",
    "            Y_f = Variable(netG(X_p, X_f, noise).data)\n",
    "            Y_f_enc, Y_f_dec = netD(Y_f)\n",
    "\n",
    "            # batchwise MMD2 loss between X_f and Y_f\n",
    "            D_mmd2 = mmd_util.batch_mmd2_loss(X_f_enc, Y_f_enc, sigma_var)\n",
    "\n",
    "            # batchwise MMD loss between X_p and X_f\n",
    "            mmd2_real = mmd_util.batch_mmd2_loss(X_p_enc, X_f_enc, sigma_var)\n",
    "\n",
    "            # reconstruction loss\n",
    "            real_L2_loss = torch.mean((X_f - X_f_dec)**2)\n",
    "            #real_L2_loss = torch.mean((X_p - X_p_dec)**2)\n",
    "            fake_L2_loss = torch.mean((Y_f - Y_f_dec)**2)\n",
    "            #fake_L2_loss = torch.mean((Y_f - Y_f_dec)**2) * 0.0\n",
    "\n",
    "            # update netD\n",
    "            netD.zero_grad()\n",
    "            lossD = D_mmd2.mean() - lambda_ae * (real_L2_loss + fake_L2_loss) - lambda_real * mmd2_real.mean()\n",
    "            #lossD = 0.0 * D_mmd2.mean() - lambda_ae * (real_L2_loss + fake_L2_loss) - lambda_real * mmd2_real.mean()\n",
    "            #lossD = -real_L2_loss\n",
    "            lossD.backward(mone)\n",
    "            optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network\n",
    "        ############################\n",
    "        for p in netD.parameters():\n",
    "            p.requires_grad = False  # to avoid computation\n",
    "\n",
    "        if bidx == n_batchs:\n",
    "            break\n",
    "\n",
    "        inputs = next(trn_loader)\n",
    "        X_p, X_f = inputs[0], inputs[1]\n",
    "        batch_size = X_p.size(0)\n",
    "        bidx += 1\n",
    "\n",
    "        # real data\n",
    "        X_f_enc, X_f_dec = netD(X_f)\n",
    "\n",
    "        # fake data\n",
    "        noise = torch.cuda.FloatTensor(1, batch_size, args['RNN_hid_dim']).normal_(0, 1)\n",
    "        noise = Variable(noise)\n",
    "        Y_f = netG(X_p, X_f, noise)\n",
    "        Y_f_enc, Y_f_dec = netD(Y_f)\n",
    "\n",
    "        # batchwise MMD2 loss between X_f and Y_f\n",
    "        G_mmd2 = mmd_util.batch_mmd2_loss(X_f_enc, Y_f_enc, sigma_var)\n",
    "\n",
    "        # update netG\n",
    "        netG.zero_grad()\n",
    "        lossG = G_mmd2.mean()\n",
    "        #lossG = 0.0 * G_mmd2.mean()\n",
    "        lossG.backward(one)\n",
    "        optimizerG.step()\n",
    "\n",
    "        #G_mmd2 = Variable(torch.FloatTensor(batch_size).zero_())\n",
    "        gen_iterations += 1\n",
    "\n",
    "        #print('D_mmd2:', D_mmd2.mean().item())\n",
    "\n",
    "        print('[%5d/%5d] [%5d/%5d] [%6d] D_mmd2 %.4e G_mmd2 %.4e mmd2_real %.4e real_L2 %.6f fake_L2 %.6f'\n",
    "              % (epoch, args['max_iter'], bidx, n_batchs, gen_iterations,\n",
    "                 D_mmd2.mean().item(), G_mmd2.mean().item(), mmd2_real.mean().item(),\n",
    "                 real_L2_loss.item(), fake_L2_loss.item()))\n",
    "\n",
    "        if gen_iterations % args['eval_freq'] == 0:\n",
    "            # ========= Main block for evaluate MMD(X_p_enc, X_f_enc) on RNN codespace  =========#\n",
    "            val_dict = valid_epoch(Data, Data.val_set, netD, args['batch_size'], Y_val, L_val)\n",
    "            tst_dict = valid_epoch(Data, Data.tst_set, netD, args['batch_size'], Y_tst, L_tst)\n",
    "            total_time = time.time() - start_time\n",
    "            print('iter %4d tm %4.2fm val_mse %.1f val_mae %.1f val_auc %.6f'\n",
    "                    % (epoch, total_time / 60.0, val_dict['mse'], val_dict['mae'], val_dict['auc']), end='')\n",
    "\n",
    "            print (\" tst_mse %.1f tst_mae %.1f tst_auc %.6f\" % (tst_dict['mse'], tst_dict['mae'], tst_dict['auc']), end='')\n",
    "\n",
    "            assert(np.isnan(val_dict['auc']) != True)\n",
    "            #if val_dict['auc'] > best_val_auc:\n",
    "            #if val_dict['auc'] > best_val_auc and mmd2_real.mean().data[0] < best_mmd_real:\n",
    "            if mmd2_real.mean().item() < best_mmd_real:\n",
    "                best_mmd_real = mmd2_real.mean().item()\n",
    "                best_val_mae = val_dict['mae']\n",
    "                best_val_auc = val_dict['auc']\n",
    "                best_tst_auc = tst_dict['auc']\n",
    "                best_epoch = epoch\n",
    "                save_pred_name = '%s/pred.pkl' % (args['save_path'])\n",
    "                with open(save_pred_name, 'wb') as f:\n",
    "                    pickle.dump(tst_dict, f)\n",
    "                torch.save(netG.state_dict(), '%s/netG.pkl' % (args['save_path']))\n",
    "                torch.save(netD.state_dict(), '%s/netD.pkl' % (args['save_path']))\n",
    "            print(\" [best_val_auc %.6f best_tst_auc %.6f best_epoch %3d]\" % (best_val_auc, best_tst_auc, best_epoch))\n",
    "\n",
    "        # stopping condition\n",
    "        #if best_mmd_real < 1e-4:\n",
    "        #if mmd2_real.mean().item() < 1e-5:\n",
    "        #    exit(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
