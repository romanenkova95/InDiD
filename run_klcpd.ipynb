{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71606f59",
   "metadata": {},
   "source": [
    "# Reorganize KL-CPD code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c0b6576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch\n",
    "\n",
    "from optim import Optim\n",
    "\n",
    "import mmd_util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab5ec3c",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e63aef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import math\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class CustomDataLoader(object):\n",
    "    def __init__(self, args, trn_ratio=0.6, val_ratio=0.8):\n",
    "        self.device = args['device']\n",
    "        #self.cuda = True\n",
    "        self.data_path = args['data_path']\n",
    "        self.p_wnd_dim = 25\n",
    "        self.f_wnd_dim = args['wnd_dim']\n",
    "        self.sub_dim = args['sub_dim']\n",
    "        self.batch_size = args['batch_size']\n",
    "\n",
    "        # load data\n",
    "        self.load_data(trn_ratio=trn_ratio, val_ratio=val_ratio)\n",
    "\n",
    "        # prepare data\n",
    "        self.prepare_data()\n",
    "\n",
    "        # split data into trn/val/tst set\n",
    "        self.split_data()\n",
    "\n",
    "    # load data\n",
    "    def load_data(self, trn_ratio=0.6, val_ratio=0.8):\n",
    "        assert(os.path.lexists(self.data_path))\n",
    "        dataset = sio.loadmat(self.data_path)\n",
    "        self.Y = dataset['Y']                                   # Y: time series data, time length x number of variables\n",
    "        self.L = dataset['L']                                   # L: label of anomaly, time length x 1\n",
    "        self.T, self.D = self.Y.shape                           # T: time length; D: variable dimension\n",
    "        self.n_trn = int(np.ceil(self.T * trn_ratio))           # n_trn: first index of val set\n",
    "        self.n_val = int(np.ceil(self.T * val_ratio))           # n_val: first index of tst set\n",
    "        self.var_dim = self.D * self.sub_dim\n",
    "        \n",
    "        return dataset\n",
    "\n",
    "    # prepare subspace data (Hankel matrix)\n",
    "    def prepare_data(self):\n",
    "        # T x D x sub_dim\n",
    "        self.Y_subspace = np.zeros((self.T, self.D, self.sub_dim))\n",
    "        for t in range(self.sub_dim, self.T):\n",
    "            for d in range(self.D):\n",
    "                self.Y_subspace[t, d, :] = self.Y[t - self.sub_dim + 1 : t + 1, d].flatten()\n",
    "\n",
    "        # Y_subspace is now T x (D x sub_dim)\n",
    "        self.Y_subspace = self.Y_subspace.reshape(self.T, -1)\n",
    "        \n",
    "        return self.Y_subspace\n",
    "\n",
    "    # split data into trn/val/tst set\n",
    "    def split_data(self):\n",
    "        trn_set_idx = range(self.p_wnd_dim, self.n_trn)\n",
    "        val_set_idx = range(self.n_trn, self.n_val)\n",
    "        tst_set_idx = range(self.n_val, self.T)\n",
    "        print('n_trn ', len(trn_set_idx), 'n_val ', len(val_set_idx), 'n_tst ', len(tst_set_idx))\n",
    "        self.trn_set = self.__batchify(trn_set_idx)\n",
    "        self.val_set = self.__batchify(val_set_idx)\n",
    "        self.tst_set = self.__batchify(tst_set_idx)\n",
    "        \n",
    "        return self.trn_set, self.tst_set, self.val_set\n",
    "\n",
    "    # convert augmented data in Hankel matrix to origin time series\n",
    "    # input: X_f, whose shape is batch_size x seq_len x (D*sub_dim)\n",
    "    # output: Y_t, whose shape is batch_size x D\n",
    "    def repack_data(self, X_f, batch_size):\n",
    "        Y_t = X_f[:, 0, :].contiguous().view(batch_size, self.D, self.sub_dim)\n",
    "        return Y_t[:, :, -1]\n",
    "\n",
    "    def __batchify(self, idx_set):\n",
    "        n = len(idx_set)\n",
    "        L = torch.zeros((n, 1))                             # anomaly label\n",
    "        Y = torch.zeros((n, self.D))                        # true signal\n",
    "        X_p = torch.zeros((n, self.p_wnd_dim, self.var_dim))  # past window buffer\n",
    "        X_f = torch.zeros((n, self.f_wnd_dim, self.var_dim))  # future window buffer\n",
    "\n",
    "        # XXX: dirty trick to augment the last buffer\n",
    "        data = np.concatenate((self.Y_subspace, self.Y_subspace[-self.f_wnd_dim:, :]))\n",
    "        for i in range(n):\n",
    "            l = idx_set[i] - self.p_wnd_dim\n",
    "            m = idx_set[i]\n",
    "            u = idx_set[i] + self.f_wnd_dim\n",
    "            X_p[i, :, :] = torch.from_numpy(data[l:m, :])\n",
    "            X_f[i, :, :] = torch.from_numpy(data[m:u, :])\n",
    "            Y[i, :] = torch.from_numpy(self.Y[m, :])\n",
    "            L[i] = torch.from_numpy(self.L[m])\n",
    "        return {'X_p': X_p, 'X_f': X_f, 'Y': Y, 'L': L}\n",
    "    \n",
    "    def get_dataloader(self, data_set, batch_size, shuffle=False):\n",
    "        data = []\n",
    "        X_p, X_f = data_set['X_p'], data_set['X_f']\n",
    "        Y, L = data_set['Y'], data_set['L']\n",
    "        length = len(Y)\n",
    "        if shuffle:\n",
    "            index = torch.randperm(length)\n",
    "        else:\n",
    "            index = torch.LongTensor(range(length))\n",
    "        s_idx = 0\n",
    "        while (s_idx < length):\n",
    "            e_idx = min(length, s_idx + batch_size)\n",
    "            excerpt = index[s_idx:e_idx]\n",
    "            X_p_batch, X_f_batch = X_p[excerpt], X_f[excerpt]\n",
    "            Y_batch, L_batch = Y[excerpt], L[excerpt]\n",
    "            \n",
    "            batch = [Variable(X_p_batch), \n",
    "                     Variable(X_f_batch), \n",
    "                     Variable(Y_batch), \n",
    "                     Variable(L_batch)]\n",
    "            \n",
    "            # не работает, оставил пока Variables\n",
    "            #X_p_batch.requires_grad=True\n",
    "            #X_f_batch.requires_grad=True\n",
    "            #Y_batch.requires_grad=True\n",
    "            #L_batch.requires_grad=True\n",
    "            #batch = [X_p_batch, X_f_batch, Y_batch, L_batch]\n",
    "            \n",
    "            data.append(batch)\n",
    "            #data.extend(batch)\n",
    "            s_idx += batch_size\n",
    "        \n",
    "        return DataLoader(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e08c61",
   "metadata": {},
   "source": [
    "## Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fee1321",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetG(nn.Module):\n",
    "    def __init__(self, args, data, device) -> None:\n",
    "            \n",
    "        super(NetG, self).__init__()\n",
    "        self.device = device\n",
    "        self.wnd_dim = args['wnd_dim']\n",
    "        self.var_dim = data.var_dim\n",
    "        self.D = data.D\n",
    "        self.RNN_hid_dim = args['RNN_hid_dim']\n",
    "\n",
    "        self.rnn_enc_layer = nn.GRU(self.var_dim, self.RNN_hid_dim, num_layers=1, batch_first=True)\n",
    "        self.rnn_dec_layer = nn.GRU(self.var_dim, self.RNN_hid_dim, num_layers=1, batch_first=True)\n",
    "        self.fc_layer = nn.Linear(self.RNN_hid_dim, self.var_dim)\n",
    "\n",
    "    # X_p:   batch_size x wnd_dim x var_dim (Encoder input)\n",
    "    # X_f:   batch_size x wnd_dim x var_dim (Decoder input)\n",
    "    # h_t:   1 x batch_size x RNN_hid_dim\n",
    "    # noise: 1 x batch_size x RNN_hid_dim\n",
    "    \n",
    "    def forward(self, X_p, X_f, noise) -> torch.Tensor:\n",
    "        \n",
    "        X_p.to(self.device)\n",
    "        X_f.to(self.device)\n",
    "        \n",
    "        X_p_enc, h_t = self.rnn_enc_layer(X_p)\n",
    "        X_f_shft = self.shft_right_one(X_f)\n",
    "        hidden = h_t + noise\n",
    "        Y_f, _ = self.rnn_dec_layer(X_f_shft, hidden)\n",
    "        output = self.fc_layer(Y_f).to(device)\n",
    "        return output\n",
    "\n",
    "    def shft_right_one(self, X) -> torch.Tensor:\n",
    "        X_shft = X.clone()\n",
    "        X_shft[:, 0, :].data.fill_(0)\n",
    "        X_shft[:, 1:, :] = X[:, :-1, :]\n",
    "        return X_shft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00282fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetD(nn.Module):\n",
    "    def __init__(self, args, data, device) -> None:\n",
    "        super(NetD, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.wnd_dim = args['wnd_dim']\n",
    "        self.var_dim = data.var_dim\n",
    "        self.D = data.D\n",
    "        self.RNN_hid_dim = args['RNN_hid_dim']\n",
    "\n",
    "        self.rnn_enc_layer = nn.GRU(self.var_dim, self.RNN_hid_dim, batch_first=True)\n",
    "        self.rnn_dec_layer = nn.GRU(self.RNN_hid_dim, self.var_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, X) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "        X.to(self.device)\n",
    "        X_enc, _ = self.rnn_enc_layer(X)\n",
    "        X_dec, _ = self.rnn_dec_layer(X_enc)\n",
    "        X_enc.to(device)\n",
    "        X_dec.to(device)\n",
    "        return X_enc, X_dec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1673f96a",
   "metadata": {},
   "source": [
    "## MMD Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "835d0087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMDLossD(X_f, \n",
    "             Y_f,\n",
    "             X_f_enc,      # real (initial)   subseq (future window)\n",
    "             Y_f_enc,      # fake (generated) subseq (future window)\n",
    "             X_p_enc,      # real (initial)   subseq (past window)\n",
    "             X_f_dec,\n",
    "             Y_f_dec,\n",
    "             lambda_ae,   \n",
    "             lambda_real,\n",
    "             sigma_var):\n",
    "    \n",
    "    # batchwise MMD2 loss between X_f and Y_f\n",
    "    D_mmd2 = mmd_util.batch_mmd2_loss(X_f_enc, Y_f_enc, sigma_var)\n",
    "    \n",
    "    # batchwise MMD2 loss between X_p and X_f\n",
    "    mmd2_real = mmd_util.batch_mmd2_loss(X_p_enc, X_f_enc, sigma_var)\n",
    "    \n",
    "    # reconstruction loss\n",
    "    real_L2_loss = torch.mean((X_f - X_f_dec)**2)\n",
    "    fake_L2_loss = torch.mean((Y_f - Y_f_dec)**2)\n",
    "    \n",
    "    lossD = D_mmd2.mean() - lambda_ae * (real_L2_loss + fake_L2_loss) - lambda_real * mmd2_real.mean()\n",
    "    \n",
    "    return lossD.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654b3a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MMDLossG: G_mmd2 = mmd_util.batch_mmd2_loss(X_f_enc, Y_f_enc, sigma_var)\n",
    "          lossG = G_mmd2.mean()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eeb914cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLCPD(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        netG: nn.Module,\n",
    "        netD: nn.Module,\n",
    "        args: dict\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.args = args\n",
    "        self.netG = netG\n",
    "        self.netD = netD\n",
    "        \n",
    "        self.data = CustomDataLoader(args=args, trn_ratio=args['trn_ratio'], val_ratio=args['val_ratio'])\n",
    "                \n",
    "        sigma_list = mmd_util.median_heuristic(self.data.Y_subspace, beta=.5)\n",
    "        self.sigma_var = torch.FloatTensor(sigma_list)\n",
    "    \n",
    "        \n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        X_p, X_f = inputs[0][0], inputs[1][0]\n",
    "\n",
    "        batch_size = X_p.size(0)\n",
    "\n",
    "        X_p_enc, _ = self.netD(X_p)\n",
    "        X_f_enc, _ = self.netD(X_f)\n",
    "        Y_pred = mmd_util.batch_mmd2_loss(X_p_enc, X_f_enc, self.sigma_var)\n",
    "        \n",
    "        return Y_pred\n",
    "    \n",
    "    def training_step(self, batch, batch_idx, optimizer_idx) -> torch.Tensor:\n",
    "        \n",
    "        # optimize discriminator (netD)\n",
    "        if optimizer_idx == 1:\n",
    "            \n",
    "            X_p, X_f, Y_true = batch[0][0], batch[1][0], batch[2][0]  # Y_true is not used! -> for validation only\n",
    "\n",
    "            batch_size = X_p.size(0)\n",
    "\n",
    "            # real data\n",
    "            X_p_enc, X_p_dec = self.netD(X_p)\n",
    "            X_f_enc, X_f_dec = self.netD(X_f)\n",
    "\n",
    "            # fake data\n",
    "            noise = torch.FloatTensor(1, batch_size, args['RNN_hid_dim']).normal_(0, 1)\n",
    "            noise = Variable(noise, volatile=True) # total freeze netG\n",
    "\n",
    "            Y_f = Variable(self.netG(X_p, X_f, noise))\n",
    "            Y_f_enc, Y_f_dec = self.netD(Y_f)\n",
    "            \n",
    "            lossD = (-1) * MMDLossD(X_f, Y_f, X_f_enc, Y_f_enc, X_p_enc, X_f_dec, Y_f_dec,\n",
    "                                    self.args['lambda_ae'], self.args['lambda_real'], self.sigma_var)\n",
    "            \n",
    "            self.log(\"train_loss_D\", lossD, on_step=True, prog_bar=True)\n",
    "\n",
    "            return lossD\n",
    "        \n",
    "        # optimize generator (netG)\n",
    "        if optimizer_idx == 0:\n",
    "\n",
    "            X_p, X_f = batch[0][0], batch[1][0]\n",
    "            batch_size = X_p.size(0)\n",
    "            \n",
    "            # real data\n",
    "            X_f_enc, X_f_dec = self.netD(X_f)\n",
    "\n",
    "            # fake data\n",
    "            noise = torch.FloatTensor(1, batch_size, args['RNN_hid_dim']).normal_(0, 1)\n",
    "            noise = Variable(noise)\n",
    "            Y_f = self.netG(X_p, X_f, noise)\n",
    "            Y_f_enc, Y_f_dec = self.netD(Y_f)\n",
    "\n",
    "            # batchwise MMD2 loss between X_f and Y_f\n",
    "            G_mmd2 = mmd_util.batch_mmd2_loss(X_f_enc, Y_f_enc, self.sigma_var)\n",
    "            lossG = G_mmd2.mean()\n",
    "            \n",
    "            self.log(\"train_loss_G\", lossG, on_step=True, prog_bar=True)\n",
    "            \n",
    "            return lossG\n",
    "    '''\n",
    "    def validation_step() -> torch.Tensor:\n",
    "        \n",
    "        return None\n",
    "    '''\n",
    "    def configure_optimizers(self) -> Tuple[torch.optim.Optimizer, torch.optim.Optimizer]:\n",
    "        optimizerG = torch.optim.Adam(self.netG.parameters(), \n",
    "                                      lr=self.args['lr'], \n",
    "                                      #grad_clip=self.args['grad_clip'], \n",
    "                                      weight_decay=self.args['weight_decay'])\n",
    "                                      #momentum=self.args['momentum'])\n",
    "        \n",
    "        optimizerD = torch.optim.Adam(netD.parameters(),\n",
    "                                      lr=self.args['lr'],\n",
    "                                      #grad_clip=self.args['grad_clip'],\n",
    "                                      weight_decay=self.args['weight_decay'])\n",
    "                                      #momentum=self.args['momentum'])\n",
    "        \n",
    "        return optimizerG, optimizerD\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return self.data.get_dataloader(data_set=self.data.trn_set,\n",
    "                                        batch_size=self.args['batch_size'],\n",
    "                                        shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return self.data.get_dataloader(data_set=self.data.val_set,\n",
    "                                        batch_size=self.args['batch_size'],\n",
    "                                        shuffle=False)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return self.data.get_dataloder(data_set=self.data.tst_set,\n",
    "                                       batch_size=self.args['batch_size'],\n",
    "                                       shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "328a7978",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args['data_path'] = '/home/eromanenkova/Intern_CPD/Alex/new_code/klcpd_code/data/beedance/beedance-1.mat'\n",
    "args['trn_ratio'] = 0.6\n",
    "args['val_ratio'] = 0.8\n",
    "args['gpu'] = 0\n",
    "#args['cuda'] = False\n",
    "args['device'] = 'cpu'\n",
    "args['random_seed'] = 1126\n",
    "args['wnd_dim'] = 10\n",
    "args['sub_dim'] = 1\n",
    "args['RNN_hid_dim'] = 10\n",
    "args['batch_size'] = 128\n",
    "args['max_iter'] = 100\n",
    "args['optim'] = 'adam'\n",
    "args['lr'] = 3e-4\n",
    "args['weight_decay'] = 0.\n",
    "args['momentum'] = 0.\n",
    "args['grad_clip'] = 10\n",
    "args['eval_freq'] = 50\n",
    "args['CRITIC_ITERS'] = 5\n",
    "args['weight_clip'] = .1\n",
    "args['lambda_ae'] = 0.001\n",
    "args['lambda_real'] = 0.1\n",
    "args['save_path'] = '/home/eromanenkova/Intern_CPD/Alex/new_code/klcpd_code/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffe3e989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = args['device']\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95299a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_trn  610 n_val  211 n_tst  211\n"
     ]
    }
   ],
   "source": [
    "Data = CustomDataLoader(args=args, trn_ratio=args['trn_ratio'], val_ratio=args['val_ratio'])\n",
    "netG = NetG(args, Data, device)\n",
    "netD = NetD(args, Data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca89f01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_trn  610 n_val  211 n_tst  211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KLCPD(\n",
       "  (netG): NetG(\n",
       "    (rnn_enc_layer): GRU(3, 10, batch_first=True)\n",
       "    (rnn_dec_layer): GRU(3, 10, batch_first=True)\n",
       "    (fc_layer): Linear(in_features=10, out_features=3, bias=True)\n",
       "  )\n",
       "  (netD): NetD(\n",
       "    (rnn_enc_layer): GRU(3, 10, batch_first=True)\n",
       "    (rnn_dec_layer): GRU(10, 3, batch_first=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_cpd_model = KLCPD(netG, netD, args)\n",
    "kl_cpd_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4d88467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ni = 0\\nfor inputs in Data.get_batches(Data.tst_set, batch_size=128):\\n    print(i)\\n    #print('inputs:', inputs)\\n    #print('inputs, X_p:', inputs[0])\\n    print('X_p size', inputs[0].size())\\n    #print('inputs, X_f:', inputs[1])\\n    print('X_f size', inputs[1].size())\\n\\n    print('preds: ', kl_cpd_model(inputs))\\n    print('preds size: ', kl_cpd_model(inputs).size())\\n    print('-------------------------')\\n    i += 1\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "i = 0\n",
    "for inputs in Data.get_batches(Data.tst_set, batch_size=128):\n",
    "    print(i)\n",
    "    #print('inputs:', inputs)\n",
    "    #print('inputs, X_p:', inputs[0])\n",
    "    print('X_p size', inputs[0].size())\n",
    "    #print('inputs, X_f:', inputs[1])\n",
    "    print('X_f size', inputs[1].size())\n",
    "\n",
    "    print('preds: ', kl_cpd_model(inputs))\n",
    "    print('preds size: ', kl_cpd_model(inputs).size())\n",
    "    print('-------------------------')\n",
    "    i += 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "723908b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "inputs, X_p: tensor([[[[0.0329, 0.5202, 0.5342],\n",
      "          [0.0110, 0.5202, 0.7105],\n",
      "          [0.0000, 0.5305, 0.4355],\n",
      "          ...,\n",
      "          [0.1834, 0.5573, 0.4651],\n",
      "          [0.1678, 0.5144, 0.5982],\n",
      "          [0.1956, 0.5608, 0.3587]],\n",
      "\n",
      "         [[0.0110, 0.5202, 0.7105],\n",
      "          [0.0000, 0.5305, 0.4355],\n",
      "          [0.0110, 0.5614, 0.4302],\n",
      "          ...,\n",
      "          [0.1678, 0.5144, 0.5982],\n",
      "          [0.1956, 0.5608, 0.3587],\n",
      "          [0.2039, 0.5170, 0.6962]],\n",
      "\n",
      "         [[0.0000, 0.5305, 0.4355],\n",
      "          [0.0110, 0.5614, 0.4302],\n",
      "          [0.0329, 0.5614, 0.5269],\n",
      "          ...,\n",
      "          [0.1956, 0.5608, 0.3587],\n",
      "          [0.2039, 0.5170, 0.6962],\n",
      "          [0.2126, 0.5173, 0.5163]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.3805, 0.7468, 0.5543],\n",
      "          [0.3711, 0.7085, 0.5416],\n",
      "          [0.3473, 0.6946, 0.4791],\n",
      "          ...,\n",
      "          [0.5100, 0.6877, 0.4941],\n",
      "          [0.5099, 0.7374, 0.5985],\n",
      "          [0.5045, 0.6968, 0.7804]],\n",
      "\n",
      "         [[0.3711, 0.7085, 0.5416],\n",
      "          [0.3473, 0.6946, 0.4791],\n",
      "          [0.3824, 0.7130, 0.5662],\n",
      "          ...,\n",
      "          [0.5099, 0.7374, 0.5985],\n",
      "          [0.5045, 0.6968, 0.7804],\n",
      "          [0.5543, 0.7263, 0.2684]],\n",
      "\n",
      "         [[0.3473, 0.6946, 0.4791],\n",
      "          [0.3824, 0.7130, 0.5662],\n",
      "          [0.3479, 0.6794, 0.4909],\n",
      "          ...,\n",
      "          [0.5045, 0.6968, 0.7804],\n",
      "          [0.5543, 0.7263, 0.2684],\n",
      "          [0.5521, 0.6820, 0.4592]]]])\n",
      "X_p size torch.Size([1, 128, 25, 3])\n",
      "inputs, X_f: tensor([[[[0.2039, 0.5170, 0.6962],\n",
      "          [0.2126, 0.5173, 0.5163],\n",
      "          [0.2155, 0.5547, 0.3307],\n",
      "          ...,\n",
      "          [0.2260, 0.5492, 0.4234],\n",
      "          [0.2146, 0.5268, 0.6106],\n",
      "          [0.2541, 0.5657, 0.3784]],\n",
      "\n",
      "         [[0.2126, 0.5173, 0.5163],\n",
      "          [0.2155, 0.5547, 0.3307],\n",
      "          [0.2017, 0.5082, 0.7510],\n",
      "          ...,\n",
      "          [0.2146, 0.5268, 0.6106],\n",
      "          [0.2541, 0.5657, 0.3784],\n",
      "          [0.2269, 0.5268, 0.4617]],\n",
      "\n",
      "         [[0.2155, 0.5547, 0.3307],\n",
      "          [0.2017, 0.5082, 0.7510],\n",
      "          [0.2194, 0.5437, 0.4222],\n",
      "          ...,\n",
      "          [0.2541, 0.5657, 0.3784],\n",
      "          [0.2269, 0.5268, 0.4617],\n",
      "          [0.2375, 0.5663, 0.5938]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.5543, 0.7263, 0.2684],\n",
      "          [0.5521, 0.6820, 0.4592],\n",
      "          [0.5521, 0.7183, 0.5058],\n",
      "          ...,\n",
      "          [0.6377, 0.6821, 0.4517],\n",
      "          [0.5981, 0.6421, 0.4418],\n",
      "          [0.6556, 0.6784, 0.5316]],\n",
      "\n",
      "         [[0.5521, 0.6820, 0.4592],\n",
      "          [0.5521, 0.7183, 0.5058],\n",
      "          [0.5646, 0.6983, 0.4982],\n",
      "          ...,\n",
      "          [0.5981, 0.6421, 0.4418],\n",
      "          [0.6556, 0.6784, 0.5316],\n",
      "          [0.6323, 0.6327, 0.4944]],\n",
      "\n",
      "         [[0.5521, 0.7183, 0.5058],\n",
      "          [0.5646, 0.6983, 0.4982],\n",
      "          [0.5677, 0.7150, 0.5385],\n",
      "          ...,\n",
      "          [0.6556, 0.6784, 0.5316],\n",
      "          [0.6323, 0.6327, 0.4944],\n",
      "          [0.6415, 0.6677, 0.5460]]]])\n",
      "X_f size torch.Size([1, 128, 10, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eromanenkova/Intern_CPD/Alex/new_code/klcpd_code/mmd_util.py:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  sigma_samples = F.softmax(U * gumbel_lmd).matmul(sigma_var)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:  tensor([1.0064, 0.9044, 0.8421, 0.8269, 0.7617, 0.7362, 0.7478, 0.7158, 0.7594,\n",
      "        0.7479, 0.7760, 0.7825, 0.7785, 0.8150, 0.8603, 0.8499, 0.8856, 0.9783,\n",
      "        0.9578, 0.9728, 1.0343, 1.0389, 0.9958, 1.0200, 0.9461, 0.9718, 0.9863,\n",
      "        0.9984, 1.0495, 1.0560, 1.1592, 1.1732, 1.3867, 1.3764, 1.3999, 1.4027,\n",
      "        1.5239, 1.5906, 1.5749, 1.6259, 1.6717, 1.5852, 1.5570, 1.5133, 1.3878,\n",
      "        1.3377, 1.3158, 1.2272, 1.1697, 1.0368, 0.8910, 0.8285, 0.7763, 0.7351,\n",
      "        0.6426, 0.6119, 0.5494, 0.5377, 0.5526, 0.5624, 0.6294, 0.6962, 0.8196,\n",
      "        1.0219, 1.1108, 1.2353, 1.3677, 1.4300, 1.4236, 1.4306, 1.4406, 1.5324,\n",
      "        1.5173, 1.5500, 1.6200, 1.6691, 1.6294, 1.6819, 1.6444, 1.5413, 1.6238,\n",
      "        1.5449, 1.5747, 1.6442, 1.7012, 1.6466, 1.7600, 1.7154, 1.7155, 1.5969,\n",
      "        1.6107, 1.4532, 1.3719, 1.3200, 1.1798, 1.1351, 1.0369, 1.0821, 1.0282,\n",
      "        1.0067, 0.8983, 0.9435, 0.9222, 0.8765, 0.8531, 0.8069, 0.8042, 0.7782,\n",
      "        0.7517, 0.7723, 0.7587, 0.7839, 0.8111, 0.8337, 0.8525, 0.9166, 0.8825,\n",
      "        0.8795, 0.8836, 0.8563, 0.8840, 0.8520, 0.9019, 0.9929, 1.0196, 1.0290,\n",
      "        1.0457, 1.0971], grad_fn=<SumBackward1>)\n",
      "-------------------------\n",
      "1\n",
      "inputs, X_p: tensor([[[[0.3824, 0.7130, 0.5662],\n",
      "          [0.3479, 0.6794, 0.4909],\n",
      "          [0.3469, 0.6937, 0.7770],\n",
      "          ...,\n",
      "          [0.5543, 0.7263, 0.2684],\n",
      "          [0.5521, 0.6820, 0.4592],\n",
      "          [0.5521, 0.7183, 0.5058]],\n",
      "\n",
      "         [[0.3479, 0.6794, 0.4909],\n",
      "          [0.3469, 0.6937, 0.7770],\n",
      "          [0.3568, 0.6847, 0.2505],\n",
      "          ...,\n",
      "          [0.5521, 0.6820, 0.4592],\n",
      "          [0.5521, 0.7183, 0.5058],\n",
      "          [0.5646, 0.6983, 0.4982]],\n",
      "\n",
      "         [[0.3469, 0.6937, 0.7770],\n",
      "          [0.3568, 0.6847, 0.2505],\n",
      "          [0.3959, 0.7221, 0.5453],\n",
      "          ...,\n",
      "          [0.5521, 0.7183, 0.5058],\n",
      "          [0.5646, 0.6983, 0.4982],\n",
      "          [0.5677, 0.7150, 0.5385]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0928, 0.5075, 0.4980],\n",
      "          [0.0985, 0.5047, 0.4925],\n",
      "          [0.1303, 0.5004, 0.4461],\n",
      "          ...,\n",
      "          [0.1566, 0.5404, 0.5510],\n",
      "          [0.2112, 0.5279, 0.5541],\n",
      "          [0.2267, 0.5118, 0.5031]],\n",
      "\n",
      "         [[0.0985, 0.5047, 0.4925],\n",
      "          [0.1303, 0.5004, 0.4461],\n",
      "          [0.1024, 0.5048, 0.5442],\n",
      "          ...,\n",
      "          [0.2112, 0.5279, 0.5541],\n",
      "          [0.2267, 0.5118, 0.5031],\n",
      "          [0.2247, 0.5463, 0.2842]],\n",
      "\n",
      "         [[0.1303, 0.5004, 0.4461],\n",
      "          [0.1024, 0.5048, 0.5442],\n",
      "          [0.0611, 0.5114, 0.5490],\n",
      "          ...,\n",
      "          [0.2267, 0.5118, 0.5031],\n",
      "          [0.2247, 0.5463, 0.2842],\n",
      "          [0.2535, 0.5119, 0.8078]]]])\n",
      "X_p size torch.Size([1, 96, 25, 3])\n",
      "inputs, X_f: tensor([[[[0.5646, 0.6983, 0.4982],\n",
      "          [0.5677, 0.7150, 0.5385],\n",
      "          [0.6029, 0.6587, 0.5027],\n",
      "          ...,\n",
      "          [0.6323, 0.6327, 0.4944],\n",
      "          [0.6415, 0.6677, 0.5460],\n",
      "          [0.6415, 0.6244, 0.5613]],\n",
      "\n",
      "         [[0.5677, 0.7150, 0.5385],\n",
      "          [0.6029, 0.6587, 0.5027],\n",
      "          [0.5925, 0.6395, 0.7084],\n",
      "          ...,\n",
      "          [0.6415, 0.6677, 0.5460],\n",
      "          [0.6415, 0.6244, 0.5613],\n",
      "          [0.6262, 0.6289, 0.4655]],\n",
      "\n",
      "         [[0.6029, 0.6587, 0.5027],\n",
      "          [0.5925, 0.6395, 0.7084],\n",
      "          [0.6377, 0.6821, 0.4517],\n",
      "          ...,\n",
      "          [0.6415, 0.6244, 0.5613],\n",
      "          [0.6262, 0.6289, 0.4655],\n",
      "          [0.6512, 0.6661, 0.5848]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.2247, 0.5463, 0.2842],\n",
      "          [0.2535, 0.5119, 0.8078],\n",
      "          [0.2682, 0.5695, 0.4473],\n",
      "          ...,\n",
      "          [0.1566, 0.5404, 0.5510],\n",
      "          [0.2112, 0.5279, 0.5541],\n",
      "          [0.2267, 0.5118, 0.5031]],\n",
      "\n",
      "         [[0.2535, 0.5119, 0.8078],\n",
      "          [0.2682, 0.5695, 0.4473],\n",
      "          [0.1274, 0.5116, 0.6437],\n",
      "          ...,\n",
      "          [0.2112, 0.5279, 0.5541],\n",
      "          [0.2267, 0.5118, 0.5031],\n",
      "          [0.2247, 0.5463, 0.2842]],\n",
      "\n",
      "         [[0.2682, 0.5695, 0.4473],\n",
      "          [0.1274, 0.5116, 0.6437],\n",
      "          [0.1702, 0.5127, 0.3226],\n",
      "          ...,\n",
      "          [0.2267, 0.5118, 0.5031],\n",
      "          [0.2247, 0.5463, 0.2842],\n",
      "          [0.2535, 0.5119, 0.8078]]]])\n",
      "X_f size torch.Size([1, 96, 10, 3])\n",
      "preds:  tensor([1.1893, 1.2279, 1.2075, 1.1835, 1.1543, 1.1262, 1.1273, 1.1203, 1.0631,\n",
      "        1.0952, 1.0928, 1.1233, 1.2406, 1.2724, 1.3779, 1.4605, 1.4858, 1.5796,\n",
      "        1.5879, 1.5968, 1.6215, 1.6533, 1.6625, 1.6785, 1.7131, 1.7391, 1.7222,\n",
      "        1.6314, 1.6621, 1.6531, 1.6555, 1.8270, 1.9378, 2.0715, 2.1343, 2.2176,\n",
      "        2.3464, 2.3250, 2.2900, 2.1677, 2.0982, 2.0077, 1.9609, 1.8901, 1.9180,\n",
      "        1.9324, 1.8939, 1.8841, 1.9429, 1.8547, 1.7691, 1.7780, 1.6453, 1.6399,\n",
      "        1.6641, 1.7477, 1.7046, 1.8324, 1.7851, 1.8165, 1.7630, 1.7280, 1.5904,\n",
      "        1.4847, 1.3919, 1.3228, 1.2362, 1.1977, 1.0896, 1.0431, 0.9175, 0.8222,\n",
      "        0.7448, 0.6162, 0.5589, 0.5037, 0.4178, 0.4144, 0.3759, 0.4228, 0.4705,\n",
      "        0.5215, 0.6176, 0.6602, 0.6691, 0.7072, 0.7942, 0.8136, 0.7797, 0.6816,\n",
      "        0.6190, 0.5858, 0.5399, 0.5241, 0.5140, 0.5297],\n",
      "       grad_fn=<SumBackward1>)\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "tst_dataloader = Data.get_dataloader(Data.tst_set, batch_size=128)\n",
    "i = 0\n",
    "for inputs in tst_dataloader:\n",
    "    print(i)\n",
    "    #print('inputs:', inputs)\n",
    "    #print('inputs size:')\n",
    "    print('inputs, X_p:', inputs[0])\n",
    "    print('X_p size', inputs[0].size())\n",
    "    print('inputs, X_f:', inputs[1])\n",
    "    print('X_f size', inputs[1].size())\n",
    "    print('preds: ', kl_cpd_model(inputs))\n",
    "    print('-------------------------')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b6a21ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y, L should be numpy array\n",
    "def valid_epoch(loader, data, kl_cpd_model, batch_size, Y_true, L_true):\n",
    "    #netD.eval()\n",
    "    Y_pred = []\n",
    "    for inputs in loader.get_dataloader(data, batch_size, shuffle=False):\n",
    "        X_p, X_f = inputs[0][0], inputs[1][0]\n",
    "        \n",
    "        batch_size = X_p.size(0)\n",
    "\n",
    "        X_p_enc, _ = kl_cpd_model.netD(X_p)\n",
    "        X_f_enc, _ = kl_cpd_model.netD(X_f)\n",
    "        Y_pred_batch = mmd_util.batch_mmd2_loss(X_p_enc, X_f_enc, sigma_var)\n",
    "        Y_pred.append(Y_pred_batch.data.cpu().numpy())\n",
    "    Y_pred = np.concatenate(Y_pred, axis=0)\n",
    "\n",
    "    L_pred = Y_pred\n",
    "    #fp_list, tp_list, thresholds = sklearn.metrics.roc_curve(L_true, L_pred)\n",
    "    #auc = sklearn.metrics.auc(fp_list, tp_list)\n",
    "    #eval_dict = {'Y_pred': Y_pred,\n",
    "    #             'L_pred': L_pred,\n",
    "    #             'Y_true': Y_true,\n",
    "    #             'L_true': L_true,\n",
    "    #             'mse': -1, 'mae': -1, 'auc': auc}\n",
    "    #netD.train()\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67032bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma_var: tensor([0.0397, 0.0795, 0.1589, 0.3179, 0.6357])\n"
     ]
    }
   ],
   "source": [
    "Y_tst = Data.tst_set['Y'].numpy()\n",
    "L_tst = Data.tst_set['L'].numpy()\n",
    "sigma_list = mmd_util.median_heuristic(Data.Y_subspace, beta=.5)\n",
    "sigma_var = torch.FloatTensor(sigma_list)\n",
    "print('sigma_var:', sigma_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6e0d63",
   "metadata": {},
   "source": [
    "### Before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f2f76fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eromanenkova/Intern_CPD/Alex/new_code/klcpd_code/mmd_util.py:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  sigma_samples = F.softmax(U * gumbel_lmd).matmul(sigma_var)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.29819736, 0.31684113, 0.3127071 , 0.3215282 , 0.33419958,\n",
       "       0.3582331 , 0.4005285 , 0.45032898, 0.5213737 , 0.52993226,\n",
       "       0.5588394 , 0.5415831 , 0.4876119 , 0.4571652 , 0.39258295,\n",
       "       0.36684233, 0.34979114, 0.34087414, 0.34133163, 0.34298944,\n",
       "       0.33409467, 0.33718818, 0.37093273, 0.42554256, 0.45834985,\n",
       "       0.4909198 , 0.5010994 , 0.5068238 , 0.5588223 , 0.57267964,\n",
       "       0.636568  , 0.64831454, 0.6826857 , 0.75308764, 0.7968967 ,\n",
       "       0.8373317 , 0.84835404, 0.92113227, 0.9308309 , 0.91975623,\n",
       "       0.92893374, 0.9235667 , 0.86326444, 0.85431015, 0.8490353 ,\n",
       "       0.79084224, 0.812289  , 0.8396985 , 0.8191958 , 0.7867148 ,\n",
       "       0.7710637 , 0.7718181 , 0.801338  , 0.7868718 , 0.81422323,\n",
       "       0.78938586, 0.74445444, 0.7722635 , 0.7284348 , 0.7032675 ,\n",
       "       0.7356901 , 0.7339393 , 0.809821  , 0.792623  , 0.830251  ,\n",
       "       0.846633  , 0.89843756, 0.93190366, 0.87667   , 0.9237601 ,\n",
       "       0.89349014, 0.87659377, 0.8616799 , 0.7900424 , 0.7969476 ,\n",
       "       0.6934816 , 0.6502051 , 0.5754681 , 0.5230211 , 0.4645993 ,\n",
       "       0.44458452, 0.41054663, 0.39318317, 0.3623392 , 0.34007946,\n",
       "       0.32402816, 0.31031263, 0.3117337 , 0.30016837, 0.34466615,\n",
       "       0.32309517, 0.35595548, 0.39083588, 0.39302045, 0.4085758 ,\n",
       "       0.43451646, 0.448288  , 0.46075574, 0.49561703, 0.47320816,\n",
       "       0.46024007, 0.47826385, 0.48281044, 0.4955734 , 0.5223079 ,\n",
       "       0.55741817, 0.5343068 , 0.60860425, 0.5728763 , 0.585925  ,\n",
       "       0.60626894, 0.5792745 , 0.5968081 , 0.5935081 , 0.59127045,\n",
       "       0.6062579 , 0.60019857, 0.59597653, 0.63004684, 0.6729395 ,\n",
       "       0.71688586, 0.73977286, 0.78490585, 0.8632644 , 0.81189466,\n",
       "       0.86173016, 0.8272709 , 0.8187514 , 0.7938512 , 0.8079375 ,\n",
       "       0.78950596, 0.8300138 , 0.82453233, 0.8759539 , 0.93470484,\n",
       "       0.9437922 , 1.        , 0.9404639 , 0.9335914 , 0.87257403,\n",
       "       0.8352544 , 0.76077497, 0.71438444, 0.619336  , 0.6014234 ,\n",
       "       0.5512819 , 0.54536587, 0.5706589 , 0.5782174 , 0.64856726,\n",
       "       0.7000894 , 0.7582079 , 0.7933111 , 0.8483837 , 0.9210029 ,\n",
       "       0.9015369 , 0.89739174, 0.9077318 , 0.8704477 , 0.8785668 ,\n",
       "       0.8389445 , 0.80236953, 0.7514609 , 0.7253941 , 0.6973005 ,\n",
       "       0.70981747, 0.6976339 , 0.68010163, 0.6580577 , 0.6396505 ,\n",
       "       0.6249586 , 0.6013874 , 0.58260196, 0.52311146, 0.49760357,\n",
       "       0.50092417, 0.51965165, 0.50296813, 0.5093188 , 0.46768606,\n",
       "       0.42094165, 0.36649725, 0.3154745 , 0.28929034, 0.2460497 ,\n",
       "       0.25426218, 0.24596742, 0.27010807, 0.26655602, 0.29320565,\n",
       "       0.3229609 , 0.35338247, 0.38381276, 0.4467711 , 0.4423695 ,\n",
       "       0.42585987, 0.4110133 , 0.45950985, 0.46968767, 0.51013   ,\n",
       "       0.5509816 , 0.5908884 , 0.6270499 , 0.6810475 , 0.69726086,\n",
       "       0.751705  , 0.77091   , 0.81558585, 0.768392  , 0.76995444,\n",
       "       0.75133765], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = valid_epoch(Data, Data.val_set, kl_cpd_model, args['batch_size'], Y_tst, L_tst)\n",
    "pred = pred / np.max(pred)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b60ea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "true = L_tst.flatten()\n",
    "#true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef21588c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3dcbbb9dd0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABK/klEQVR4nO2dd3gb15W33wuCJNg7KTaRVO+WZFmWIsklsRO3jWOvndiJs84msbO7cfqm7JfdbDZbs5tN9snGSdZZp7gkduzE6xL3uBfJKlYvFMXeSbCCJEASuN8fg4FAEiQKAQwwM+/z6BEBDDB3Zu79zZlzzz1HSCkxMTExMUl+LFo3wMTExMQkOpiCbmJiYqITTEE3MTEx0QmmoJuYmJjoBFPQTUxMTHSCVasdFxcXy9raWq12b2JiYpKUHDx4sF9KWRLoM80Evba2lgMHDmi1exMTE5OkRAjRMt9npsvFxMTERCeYgm5iYmKiE0xBNzExMdEJmvnQAzE1NUV7eztOp1PrpsQUm81GVVUVqampWjfFxMRERySUoLe3t5OTk0NtbS1CCK2bExOklNjtdtrb26mrq9O6OSYmJjoiqMtFCPFzIUSvEOL4PJ8LIcQPhRANQoijQoitkTbG6XRSVFSkWzEHEEJQVFSk+6cQExOT+BOKD/2XwFULfH41sNL7707gJ4tpkJ7FXMUIx2hiYhJ/ggq6lPI1YGCBTa4H7pMKe4F8IUR5tBpoEgCPG959ANzTWrckeRgfgOO/17oVMWF8cppHDrQxIxX2mWdgpEu7RmmJx2PY8RGNKJdKoM3vdbv3vTkIIe4UQhwQQhzo6+uLwq4Tm1deeYXrrrsu+j/ccRAe/yy0vhX939YrJ34Pj/45TAxq3ZKo89SRLr766FFOdY0qb0gJD30MDt2nbcO0ovOQMj5a3tC6JXEnrmGLUsp7pJTbpJTbSkoCrlxNCtxut8YNmPT+P6VtO5IJ9Vzp0GprGRgDoG1wXHlDSpBu8Bi0f/jGh/6udTCiIegdQLXf6yrve0lJc3Mza9as4WMf+xhr167lpptuYnx8nNraWr7+9a+zdetWHnnkEZ5//nl27tzJ1q1bufnmm3E4HAA8++yzrFmzhq1bt/L738foEV96vP+b1aZCxnfOPNq2Iwa0DUwA0D6o/K/nYw0JAx9/NMIWnwDuEkI8BFwMDEspF+28+4cnT3Cyc2TRjfNnXUUuf/8n64Nud+bMGe6991527drFJz/5SX784x8DUFRUxKFDh+jv7+fGG2/kxRdfJCsri+9+97t8//vf52tf+xp33HEHL730EitWrOAjH/lIVNvvw8AdNmJ0fM5aBxTLvMMUdAUDH39QQRdC/Aa4DCgWQrQDfw+kAkgpfwo8DVwDNADjwJ/HqrHxorq6ml27dgFw22238cMf/hDAJ9B79+7l5MmTvm0mJyfZuXMnp0+fpq6ujpUrV/q+e88990S/gQbusBGj43PW7nW1tPtcLvo91pAw8PEHFXQp5a1BPpfAZ6PWIi+hWNKxYnZYofo6KysLUBYHXXnllfzmN7+Zsd3hw4fj0r7zrhbT5RIyOj1nY65p+h2Kz9jnclGP0aguOZ1e61Awc7kEoLW1lbfffhuAX//61+zevXvG5zt27ODNN9+koaEBgLGxMerr61mzZg3Nzc2cO3cOYI7gRw21wxrQAokYnVptqogXZKbSMWS6XABDH78p6AFYvXo1d999N2vXrmVwcJC//Mu/nPF5SUkJv/zlL7n11lvZtGmTz91is9m45557uPbaa9m6dSulpaWxaaCBO2zE6PSctXn95zuWFTE8McWoc8qcNDewwZNQuVwSBavVygMPPDDjvebm5hmv3/ve97J///45373qqqs4ffp0LJunW3GKKTod5OqE6M7lRTxzvJuOoQnW5OvzWEPGwOPDtNCTEQN32IjRqdXaNjhOZloKGyvzAGgfmDD7h4GP3xT0WdTW1nL8eMA8ZImDgTtsxOj0nLUNjFNdkElVQSaA4kfX6dNIyOj05h0KpqAnIwbusBGjQ0E/3T3Cmw121pTnUJydRrrVwqmuEV0ea1gY+PhNH3oyYuAOGzE6O2cO1zR33HeAHJuVb16zFiEE12ws56H9bazJcfIJ0M2xho3OrnU4mBZ6ArG30c6nf7WfgbFJekacPHW0E48nkBWubZzx3kY7W//xBfodLk32Hxn6is3e12inbWCC7/7pJkpzbQD8+02buGr9Eu5++ax3K30ca/jo61qHg2mhJwg9I04+++Ah7GOT/L/fH6PZPsbp7lF2r2jjRx/dQn5m2vmNNbZAXjrdy8DYJGe6R0mtsHC4fYhLVyV4sjWdWW1q/PkG72QoQGqKhQ9tqeDQiVPKGzo51rDR2bUOB9NC92NoaMiXtyXefPOxY0xMufnwtiqePdFNfc8on9pdxxsN/Ty4r3XmxhpPer3bqqSgbR0Y5/69zdz+83fOL2pJVHQ2yNsHx0m3WijOTpvxfmV+JhZic6ydQxPc8OM3fbHvCYvOrnU4mILux3yCPj0d+zSch9uGuW5TOf98w0au21TOP31oI3933TpKctJptc8aQBp22MlpD0fbhwFF0Ot7lCyT+5sWqoGSAOhskLcPTlBVkDEnTUVFvg1LjFwOh9uGeLd1iAf2tUT1d6OOgaN8TEH34xvf+Abnzp1j8+bNXHTRRezZs4cPfvCDrFu3jubmZjZs2ODb9nvf+x7f/va3ATh37hxXXXUVF154IXv27Al7YdG024N9zMWSvAxSUyz86KNb+ejFSwGozM+gfShxBP109wiuaWW/bQPjnOtTBH1fwgu6vgZ5x9AEld5QRX8Ks9LISPW+iPKx9owodXAfO9TBtNvja4fDlWB5x3V28w6HxPWhP/MN6D4W3d9cshGu/rd5P/63f/s3jh8/zuHDh3nllVe49tprOX78OHV1dXNWivpz55138tOf/pSVK1eyb98+/uqv/oqXXnop5Gb1OyaREspy0+d8VlmQwYmO4Zlvathh320dAmB5SRYt9nEa+5TiCu802ePelrDQWahn++DEDP+5ihCC8tx0GCMGgq5MgveOuni9oZ/aoiyu/eHr3Li1kn/60Mao7mtRmIJuEojt27dTV1e34DYOh4O33nqLm2++2feeyxVe9Idq+ZTl2OZ8VpWfwQsnevB4JBaL9/FaU0EfpCw3nYuXFfHw/jbcHklNUSbn+sbod7gozp57U0oIdDTIx1zTDIxNUlWQEfDzJTES9N4RJ6U56Ux7JN958iTpVgvjk27fTT5h0NG1DpfEFfQFLOl4oabLBSW/i8dzvoM4nYoIezwe8vPzF5U61yfouXMFvbIgg0m3h36HyxeepmWHPd45wsbKfGoKM3F7QypvuWgp3332NPubBrh6Y4LWB9fRIFcnoKsCuFwAynPToIvoW+ijTioLMvjr96/m/z12jNPdo6yvyKW+ZxTXtJt0a0pU9xcxOnsaCwfTh+5HTk4Oo6OjAT8rKyujt7cXu92Oy+XiqaeeAiA3N5e6ujoeeeQRQMmVfuTIkbD22zOqWPSlAVwuqhXW7h9FopEouT2SVvs4y0uyWFp4Xkw+tKWCHJuVp493a9KukNCRD10tZDGfhV6Wo0S+qH7uaNE74qIsx8auFcU8/6VLeO6Ll/BXl61gyi2p73ZEdV+LQkfXOlxMQfejqKiIXbt2sWHDBr761a/O+Cw1NZVvfetbbN++nSuvvJI1a9b4PnvwwQe59957ueCCC1i/fj2PP/54WPvtG3FiEVCUlTbns8p8b46OQX9B16bDdo84mXR7qC3Ootor6Dk2K0tybXx4WzXPHOuie9gZ1zaFjO9cJb/Vpsagz+9yUfrRxGR0i0T3jDh98zzp1hRWL8lhQ2UuAMc7hxf6anzR0bUOl8R1uWjEr3/963k/+/znP8/nP//5Oe/X1dXx7LPPRrzPnhHF92xNmXt/rfQO2o5AFnqcBb25X5kArSnKZGmRIujLS7IRQvCJ99TyizebuH9vM1/9wJqFfkYbdORyaR+cIN1qoWSe+Yoy7/vOySlyorTPiUk3I87p824/L0sLM8mxWTnWMUz6oXZ2LCuiIj/wjSZu6Ohah4tpoScAPaPOgP5zgOx0K3kZqbMsdI0E3a4Iem1RFrm2VIqz01ldpkhGdWEmV6wt48F9rYwlWhgb6GqQtw2MU5k/NwZdpdRroTsno3cdekcDz/MIIdhQkcejB9r58m+P8PM3mqK2z4jR0bUOF1PQE4CeEVfAkEWVyvyMWRa6Ni6XFvs4aVYLS7yD+oFPb+erV632ff6ZS5czND7FA3sTcOGJjgZ5i33c94QUiKIMZXJywhU9l4sasliaM7efbqjMZdLtQYgEcb3o6FqHS8IJujTAzPTsY+wbdVISIGRRpbIg43xFd9DU5VJTmOkLn1yzJHdGmOKFNQXsWVnMPa81MjHpjmvbgpJgE2VSSv7v3Q4mvYu0hsYnQ/5es32M2qKsebexeke1wxnab4bCQpFYH7u4hq9+YDUfvrCak50j2o/hBLvW8SShBN1ms2G327XvEDFESondbsdmUwbGlNtDv2NyQQt9Y2Ue9T0OnjnW5f0RbQS9xT5ObfH8QgJw1+UrsI9N8szxrji1KkQSzGo71jHMFx8+zLMnujnQPMDWf3yB090jQb/X53AxPummdgELXT1Gh3MyamPpvKDP7ae1xVl89vIVXFCdz4hz2jdpqxkJdq3jSUJNilZVVdHe3k5fX5/WTYkpNpuNqqoqAPq8IYvz+dABPnPpMl4508uXf3uE3IxUdmnQYT0exTK8ZFXxgtttWVoAQNtAgiXrSrDYZDUaqLHPQd+oC4+EvefsrFmSu+D3mvuVJ7UFb6zeY3W73XQOO6mMwiRl76iLNKuFPF9egbmsr1DafqJz2BcFpQmmoCcGqampQVdm6o2FLB+VdGsKP/34hdxyz15uu3cfD23o52KIqzj1jDpxTXuoWeBRHyDNaqEoK42e0UQLX0ysx/B+h+IOabGPk52uDMMj7cH9z/4T0/Pi7RcCONY+HB1B94YszjcRC7B6SQ4pFsHxjhGu2qDlAjPj5kNPKJeLEXlwXyspFsHK0oUDzEpzbDz1ud1cVFPIATVvShw77JE2RWyWBXG5AJTm2ugdSTBBTzALXX0ya+ofo8kbDnq4bSjo95r7x7BaxLwx6IDvGC1CciJKk5Sdw07fZPh82FJTWFGSHbV9RkyCXet4Ygq6hrx8updHD7bzF5cuC+kRNTPNyva6QhxOb/SC9HCuz8Enf7mf4fHoLiKZza/eaqYiz8ZFdYVBt12Sm+6LikgYEuwxvM+h3PBa7OcFval/LOjkaIt9nKqCjIBrFnx4jzE7zcLx2YndIqRtYDykPrq+IpcTncHnAmJKgl3reGIKuob85NVz1BVn8fn3rQz5O9WFGQi/Dvv7Q+28dLqXJ452xqiVcLxjmLcb7XxiVy2pCwmJl7JcG90Ja6EnxiBXLfTB8Sk6hibY7r1RBnO7NPWPBZ2YVo8xJ83C8SiIq3PKTfeIc0a6h/lYX5lH76jLF7euCQl2reOJKegaIaXkVNcIu1YUhZXUqKogE+HnD36jQXG/PP5uRyyaCcB9bzeTlZbCLduXhrR9aa6Nfocr6rlEFkWCDfK+URcWP3f09ZsrEAKOzON2efRgOx+/d58i6EHmMdRjzEgV9I26cE0vLoS0Y2gCKQlN0H0Toxpa6Ql2reOJKega0T3iZNQ57VtpGSpVBRm+EmPOqWmOtQ9RnJ3OgZbBuZWNosT+5kF2rywm1zZ/hIM/ZbnpSHl+4i8hSLBB3udwsbb8fETLpsp81lfk8uC+FrqG50YIPX64g9fP9jMxFSRkEXzHmOa1E9SngUhp9ZacC0XQ13kF/aQp6JpgCrpGnO5WsjquDhKmNpvyvAwsQrHQOwYceCT83XVrAXjiSPSt9FHnFE39Y2wMUExhPtS87j2J5HZJoMUmUkr6Rl1cWFOAGjRSW5zJf9x0AWMuN5/65QHfgiOVU12jXLa6hE/uquOaTUEiSFRB9z4CLHY+oy0MQc+1pbK0MFPbidEEutbxxhR0jahXBT1MCz3NaiE3XTG92gfGyE63cs3GcjZW5vFGQ/+83xuemOIvHzgYdoFf1dJaXxG6oC/JUwQ9ofzoCWS1OVzTOKc8VBVkUJGXQXF2Ojm2VNaW5/LPN2zgZNcI+/wqQPWNuuh3uNizsoRv/ck6ShdYVQz4jjE1RXq/v7jr0Gofx5ZqoSTAsv9AbKjM5XiHaaEDPHOsi53/+se4rZwOSdCFEFcJIc4IIRqEEN8I8PlSIcTLQoh3hRBHhRDXRL+p+uJM9yhLcm3kZYbmxvAn36YIetvAODuWFZGaYuHCmgKOtA3P67d+8WQPzxzv5neH2kPax8P7W/nM/Qc45o2SWF8Z+pOEmtc9oUIXZeLEJqsukJKcdDZW5nFB1fmb5fvXLSHdauGl07202sd5eH+rbwXp2iUh3vxnWei9UXC5LC3MXDAG3Z/1FXm0Dowz4oxt5NW8JJCF/tY5O13DTl/t3VgTVNCFECnA3cDVwDrgViHEulmb/S3wWynlFuAW4MfRbqjeONMzyqpQB+gscm3KQpQx1yTXbloCKHlUJqbcPleOStvAOB6P5E2v9f7S6d6Q9vFqfR/PnejhwX2tlOakB7cK/SjKSifFIhIrdDGBcmT7BD3bxn/dspkffXSr77OMtBR2Li/ipdO9fP13R/n6747x2CHFlbamPNSbqnKMVgtYhFKYYjGogh4qmvvRE0DIVc72KuMxYQQd2A40SCkbpZSTwEPA9bO2kYDa2/KA2MXQ6YBpt4ezvQ7WRCzoioWeaoEr1pYBsLVGWXJ/sGXQt13X8ASXf+8V7n65gTca+rFaBEfbh0MKKVNFoKl/LGAx4oVIsQhKstPpHJ7g9bN9TCVCtEsCPYb3Oc5b6LbUFDLSZkY5vW9NKS32cd5uVNwuv3+3g7LcdAoDFEAJiLpSVHooyUlfVAihlDLkGHSVdd4bz+kujQU9Aa51Q68i5Oe8xdRjTSiCXgm0+b1u977nz7eB24QQ7cDTwOcC/ZAQ4k4hxAEhxAG952tZiJaBcSanPWH7z1VUQa8psJHjjTypyLOxJNc2Q9DfPmdn2iP575cb6B11cduOGgBeOR383Ps/pm+oCG/iFqAsz8b/vdvBx+99Z0HfftxIoEHu73IJxOVrSgEoz7NxzUblCSxYjpcZ+B1raY5tUS6XgbFJxibdYVnopTnpZKWl0ByjqKugJMi1Hhib9EV6NSaQhR4KtwK/lFJWAdcA9wsh5vy2lPIeKeU2KeW2kpKSKO06+Tjji3CJTNALvPmulxWfH2RCCC6sKZgh6PsaB7ClWnwRE5/eU0d5no2XzyzsdlGjMK7dWE51YQaXri4Nu41LctPx1pCmf5E+3KiQIIMcFEG3WgT58yS6qirI5DOXLuNfbtjI7TtrAVhTHkZfmSHoi1u1q/bVZSXZIX9HCEFNUZYv70zcSZBrrVrnmWkpcbPQQ0nO1QFU+72u8r7nz6eAqwCklG8LIWxAMRCaw9ZgnOkexSJgRWnog8QftQhwbeFMv/b2ukL+cKyLE53DrK/IY2+Tnd0rSshOT+Fsr4Oqgkxl8rR9aMHfd7immZhys6kqj7s/tnXBbefji1es4uoN5Xzx4cMMT2g0OeZPggxyUJ5+irLTfHnlA/E3VyuhqFJK/vbatbx/3ZLQd+CXy6Q0Nz3o9V4IdeXqpjDdbnXFWdqFLibIta7vUW6Gl68u5cVTPXg8csFrHg1CsdD3AyuFEHVCiDSUSc8nZm3TCrwPQAixFrABxvWpBOFM9yi1RVnYUkNfIeqP8GXTmznB96EtlWSnW/npq410DU/QYh9nx7JCvnfzBfz+r94DwMrSHNoHJxYMo1If0UsXyAAZjLXluVy/uYIUi2AoxnlmQiJBBjl4C4UEW+3pRQjBp/csW7BC0Rz8jrUkx4Z9bDLiVbtH2oaoKcqkIFT/vZfa4kzaBie0mT9JkGvd0OsgKy2FXSuKcU17ZlYdixFBBV1KOQ3cBTwHnEKJZjkhhPiOEOKD3s2+AtwhhDgC/Ab4hNRzlYpFcqZnNGJ3CzBvNrm8jFQ+tmMpfzjayY9fPgfAjmVFWFMsvvQCK8uykVKZdd/baOdsz8yoGDg/IRpOZEsghFDcCkMTCbhiVKvdS8nZXgcrI3w6C20n5yN6SnMWt2r3aPsQm6ryw/5ebVEWbo/UttiFxtf6bO8oK8pyWF6i3LzP9TliXrwnJB+6lPJpKeUqKeVyKeU/e9/7lpTyCe/fJ6WUu6SUF0gpN0spn49lo5MZ55SbZvsYqyKcEAUWtEA+tauO1BQL9+9tYUmubcbycsAnJGe6R/mLBw7yr8+cnvMbahRGoPqR4ZKXmWpa6H70OVwMT0xF7G4LCb9jVQunRBLp0jvqpHPYOSNOPlTUBGLN/Rr40RPgWk9OezjROcLqsmyWe6/1XzxwkPf+56tzVgFHk4QqcGEEzvY4kJKIQxYV5l84UZpr47kvXoJzWolMSJnls6spysJqETx+pJOh8Smfn88fdUFQqCsDFyI/IzXBfOjaPjiqE2XB8t8vCr+FNepNOZJY9KPeHPgXVOeH/V01gVhT/xiXh/3tRZIA1/ql070MjU9x9YZyirLSuHV7NZ1DTl6t7+Ol0z0xKwBiLv2PM2e8AhrpoiIgqAVSW5zFmiW5ZKbNvV+nWS3UFGXyWr0yxdE+OMGYa3rGNn0hlBsLlfzMNAZDLIAcUxJgkMN5QY+3hd4VwardI+1DpFiEL4NiOBRnp5GdbqVFi0iXBLjWjx5soyw3nT0rixFC8K83buLnn7iIJbk2fvNOW/AfiBBT0OPMme4R0q2W4ClQF2KRHXa2daiKjErvqIuS7IXLjYVKfobpcvGnoddBTrp1wZKDi2aWhZ6ZlhJRHHRDr4OaosyAhkEwhBDUFmfSpEUsusbXunfEyctn+rhxa9WMQiQpFsGHt1Xx2tk+2gdjc15MQY8zLfZxaormukLCYpEddmWZYh1etlpZCzDb7dI36lpUhIs/eZmpMa+mFBIJIuhnexwsL82Oys1yXvyO1WIRLCvJiigOun1wguqCyIs9ryjJ5lTXSMwnAueg8bV+/Ww/bo/k+s0Vcz778EVKBPgfjnbFZN+moMeZnlGX7zE4YhYt6IqFfuv2paRZLZydY6E7KcmOjqDnZ6Qx6prWfvl/ogh6rCNcYM6xrijJ5lxv+BZ6++D4wrVLg7BzeRF9o645/SvmaHytW+xjWAQsK557nasKMnnyrt3csWdZTPZtCnqc6Qmh2G5QFtlh37+ujH+7cSNXrC1jeUm2z0J3Trk50TlMz0j0LPR8bzbJEa0nRhNA0PsdShpc9QkpZsxyyS0vyaZjaILxyekFvjQTh2uawfEpqhZhoe9eqTwBqvM1cUPja906ME5FfgZp1sDyuqEyL2YLjExBjyNuj6TPEQ0LXX2EjexR1paqlJNLsQhWlWVztkexoP7n1Uau/eEbDE9MLToGXUUV9CHNBV37lKp/PNUDwK4VxbHd0SxBVydgG8Nwu6g+3urCyC30yvwMlhVnxT+Xj8bXuiXM7JTRxBT0OGJ3uHB7JGV52lro/qwqy6FjaIJR5xRvN/ZTV5zF5967ghu3zs6/Fhn5mcoKQ80nRhNA0J893k11YYYvG2HMmNU/1Djo2ZPfC9E+oCwIWoyFDrBnZTH7GgcWXdc0LDS+1m0DyjyZFpiCHkfUCj5au1z82eKNMX6zoZ8jbcNcuqqEr7x/9aIHsoqagGpY69WiGj+GjzineLPBzlXrl8R2QhTmHKs6CR9OTm7VQl+MDx0Ut8vElHtG0riYo+G1drim6XdMhpVuOJqYgh5HuocVQV90yFoULZBttYVkp1v5ySvnmJhyc6E3r3q08LlcNLfQtS1w8fLpXibdHq7aEEaSrYiZ2T/SrSksLcwMy0JvG5wgIzWFojBzuMxmx7JCUiyCN87G0e2i4bVWSzzWFC4iLHkRmIIeR3q8Sa8SyUJPs1rYvaLYl1Uv6oKeoQjCYKIIukaLTfY2DpCXkcqW6uie34AE6B/LS7LC9qFXFWQs+mkix5bK1qX5Pj96XGpranitW+yhF9SOBaagx5GeYScpFkHRYkMCo9xhL1+jRCOU59moyF/cI/ZscmxWhIBhrVeLauxyOdszyuqynJinTwUCPsGV5trod4S+/L99cGLR7haV3StKONYxzC/ebGLzd55nb6M9+JcWg4bXunVAuWmGlR0zipiCHke6R5T47kUtKoKod9jLvAUstkbZOgewWAR5GakJEOWi3SCXUlLfMxr7cEXfDucea6E3BYPHE5oREG7ZuYXYvbIYKeE7T53ENe3h7/7veGzXJWgq6OPkZaRGJW1GJJiCHkd6RpyLj3CBqHfYslwb37puHXfGaLFDQiz/13CQ94y4GHFOLy5lcjgEeIIryErDI5XJ2WAMT0wx4pyOmoV+QVUeOd7C5l9430rO9jr41VvNUfntgGh4rdWV4FphZluMIz0jzsXlcFGJgY/wk7vrovZbs8lLiARd2oWyqQu3Ypph0Z8Ak4KFWYrFODg+5QslnQ81oVaoRTiCYU2x8JlLluH2wBeuWMn+5gHufaOJT7yndkauk+ihzbXud7jY1zTAR7ZVB984RpgWehzpHnayJCoWuvYx1eFQXZChXX1JFQ2tNlXQV2noclFFfGAs+I1VLe4cFePDy13vXckXrlgJwCfeU0vXsJMXvQutoo5G1/q+t1uYcnv4xK7auO7XH1PQ48TEpJsR5/TiV4mC5hN84bKqLIe2gfCWnkcdDW+C9T2jFGWlLX4yPFTm8aEDDIYi6P2qhR4b18H71pZRmZ/BfW+3xOT3tbjWE5Nu7n+72ZdOQytMQY8Tah70uuJoWD3JZaGrlmk4cdBRR8NQtvoeR/wmRCGgoBV648kHQnB9NdvHKM+zRVzzNhgpFsFHL17KW+fsscmXrsG13t88wOD4FLftqInbPgNhCnqcONyqrJTbHEH1lzkkoYUOStk7zdDonEkpaeh1sHoxJQfD3mkgl4u6wCs0Cz3WE3sfvEBJLfv0se7o/7gG11q9MS2uEtniMQU9ThxuG6I0J53yBIxyiTU1RVkB0/TGFY0s9M5hJw7XtC9lcVwI0D+y062kpggGxoJHubTYx6P0JDk/1YWZXFCVx9PHYpAXXINr3TowTrrVEpU6vIvBFPQ4caR9mM3V+dHJ45EAJbbCIcUiWFGSbUgLvb5bnRCNp6DPdbkIISjITAvqQx9xTmEfm4xahMtCXLupnGMdw7RGu6qRJha6kmEx5nl6gmAKehwYGp+kqX8somK7AUkyCx3wpuk1oKDHO8IF5j3Wwqzg4aMt/dGPcJmPq72Fkp861hndH9bgWrdqmGHRH1PQ44CaJ2VLtAVdo0RTkbCyLIfOYWdIC1tigkZRLvU9Dkpy0oPGfkcV/2P0e4rLz0wNKuhNXl9wbXHsxam6MJOLagt45EB7dMvUxflaSylpHRhnqUYJufwxBT0OvHG2DyFgY1VedH4wyeLQ4XyRhaYIaltGBY0s9LO9o/GdEIV5Bb0wKy1oHHqLN2QxXsmlbt2+lKb+MfY2DkTvR+N8rfscLsYn3aaFbgQaeh386q0WPnhBBTm2KOV3SEKXi5phsnc09ARRUUWDm6DHIzkb75BFmCXo5/8uyEwLmvWya8RJYVYamWnxWUR+zcZycm1WfvNOa/R+NM7jo1XjDIv+mIIeY/7+iePYUi387bXrovejSWihl/kE3alNAzRwU7UPTjAx5Y7vhCgw4xhnxaIPBUnQ1TPsjGukhi01hRu3VvHM8S46hyai86OLLNEYLq3eHOhaZVj0xxT0GOKccvNmg53b31NLSTQHSRJa6MXZaQihJKrSBA3OmSYTojCvhZ6fGTxBV/dIlNJThMGn99QhJfzklXPR+cE4X+sW+zhCLL66UzQwBT2GqBZH1CMGklDQrSkWirLS6NPaQo/jOTvVNQIQ3xh0mFfQ1QRdC/nRe0Zciy/AEiZVBZncvK2ah/e3RcdKj7fLZWCcirwM0q2xWVkbDqagx5Aub8m5aBeNSEZBByjJsdGruYUeP5fL4bYhlpVkkRutuZNQWcCHDswb6TLl9mAfc0Un31CYfPby5Ux7PDwUDV96nK/1qa4RXyFurTEFPYZ0eK2NivwoD5AkW1ikUpqTruGkaHxvglJKDrcNRSfVQ/g79/vbr2pRjtIPz/UGjjTqG3UhJZoIelVBJttqCnn+ZBQyMMbxWk9Mujnb6+CCaEWwLZKQBF0IcZUQ4owQokEI8Y15tvmwEOKkEOKEEOLX0W1mctI1pFjoUfdJJrWga+RyiSChmZQy4gyR7YMT2Mcm2bI0DjVEZzPjGM/3kbXlOSwrzuKh/YGt4O4Rtb9qs3z9/evLON096iu0HDnxCxo42TWC2yPZWJkkgi6ESAHuBq4G1gG3CiHWzdpmJfA3wC4p5Xrgi9FvavLRNTxBcXZ69H1rSepyKc1Np98xiTvEMmhRJYJz9vKZXrb+4wv0eoVOSsn3njvj843P5pEDbTy4rwUpJe+2DQFRXEwWDvO4XIRQshweah3iZOfcY+jxugi1sNABrlxXBrB4Kz2O4+N4h7JocFNVfsz3FQqhWOjbgQYpZaOUchJ4CLh+1jZ3AHdLKQcBpJS90W1mctIxNBF9dwskZdgiKELh9siQiixEnQgG+enuUZxTHg55M2UebBnkRy838Is3m+Zs2zU8wTcfO843HzvOV357hDfP9pNutcSv7Jw/8ywsArjpwirSrRYe3Dc3F3nPiLaCXlOUxZolOTx3YpEZGOMo6EfbhynOTqcsV9ukXCqhCHol0Ob3ut37nj+rgFVCiDeFEHuFEFcF+iEhxJ1CiANCiAN9fX2RtTiJ6Bp2UpEXi1Cm5BR0Nb457m6XGT7l0J8O1AlcNXXDY+92APD62X5GnVN8+lcH+OEfz2J3uPifVxvxSMmf76rlscMdPHygjY2VeaTGpMRaEObxoYMSurhrRTEHmgfnfK17xEVqivAVw9CCazaW807TwOLcLnF0SR7rGGJTVZ7mSblUotXbrMBK4DLgVuBnQoj82RtJKe+RUm6TUm4rKSmJ0q4TEyklnUMTlMfEQk9Ol0tJjkarRedxQQRDvfEcax/GNe3mqaNd5KRb6Rp28u/PnuHFUz18/4V6LvrnF7l/bws3bKnk7/9kPU/etZsr1pZyy/al0T6S0AhyvMtLsmi2j81ZYNQz4qQ0x4bFop04/emFVQihuK8iJk5PsOOT0zT0OhLGfw6hCXoH4F/1tMr7nj/twBNSyikpZRNQjyLwhmVkYprxSXdsLPQkFXTVQu+Ld+hipILubefR9iFePt3L8MQUX7t6DQD3723hgup8nv/SJdx1+Qp2ryj21czcUJnH/95+ETddWBW9YwiHIMdbW5yFa9pD18jMJ6UeDRYVzaYyP4NLVpbwyMH2yOda4jQ+TnWN4pHK9U4UQhH0/cBKIUSdECINuAV4YtY2/4dinSOEKEZxwTRGr5nJR+ewGrJoCrpKiWYul0gtdBdWi2DEOc13njxJZX4Gt15UTa13ifftO2tYVZbDl9+/ml99cjtVBdov/QaCHq9avGJ2orTuEWdC+II/clE1XcNO9jbaI/uBOLlc1MnxteXaVinyJ6igSymngbuA54BTwG+llCeEEN8RQnzQu9lzgF0IcRJ4GfiqlDLCq6EP1BVvsXW5JFfYoi01hbyM1Pgv/19gknDer0hJz4iTHcuKAKXy0DeuXoM1xcL71y9hSa6NazaWx6K1iydUQfer53msfZj2gQkqY2GAhMn2ukKAyPPnx8ngOd09Qo7NmhDnTCWklGpSyqeBp2e99y2/vyXwZe8/E5Q82EBsLnYS5kNXKc+zRS8JU6gsMEk4HyPOaVzTHnavLOZgyyBrynO4bpMi4F/9wGo+/76VMSuivGiCTAKX5djISE3xWeiNfQ5uu3cfpbnpfHJ3XbxaOS9FWWnYUi20D0bYT+LkQz/VNcraJbkJMyEKIQq6SXiMT05z7xtNbK8tjE3muiR1uQDUFGVyLt450SNwuag5Z8rzbPzqk9upLszwDdzUFIs20SuhEuR4LRZBTVEmzV4L/TfvtDIx6ebJu3ZTHpOorPAQQlCZn7EIQY/9+PB4JGe6R7lx6+yAP21J4F4Zfc71ORhzRbbyLxx+8WYz/Q4XX796dWzu3kks6LVFWbQOjC+YwjXqRCDoqluoNMfG9rrChBC6kAnheJeVZNHsLWbx8pk+Ll5WmBDpX1WqCjJ9qTPCJg7jo2NoAodrmrXluTHbRyQYRtCdU27+5L/f4NtPnIj5vn69r5VLVpVwYU1hbHaQpAuLQFk8Mjnt8S0zjwthCPrp7hG2/dMLvgm50gSYJAybEI5XvbE29Y/R0Ovg8tWlcWpcaFQWZNA+GGEsehwE/aR3QnSNFgvHFsAwgn6oZZDxSTePH+nE7ojdpNzEpJuOoQm218Ywh0dSC7piBTbb4+h2mSe3SSBeq++j3zHJfW8rKym1WjW5OIIvpKorzmLaI/nBC/UAXL4msQS9qiCDwfGpyJ6o41Dg4nTXKEKgzUrgBTCMoL/daMciYHLaw0P7F7FoIQhq9ZKaWFZNT2KXiyroLfbFJmAKgzAmRY+0KatChyemyExLITs9CaeZQrDQL11dQmV+Bk8c6aS2KNMX+ZIoqMEEEbld4jA+TnWNUFuUFbdSfaFiHEE/Z2djVT67VhTx4N6W6FYZ90O1PKNe1MKfJBb08rwM0lIs2lnowQS9fYjUFGXeI56l2KJKCMdbmmPjyc/t5rpN5dxxybI4NSx01Jj+iNwucRgfp7tHEir+XMUQgj4+Oc2R9iF2LivivWvK6Bx2xixBVItXqGI6wZTEgp5iEVQXZtDSH08LPbQ4dLvDRfvgBB/1LtlX84cnHSHewAqz0vjRR7fysYtr4tCo8FDLuXVEEukS43UaY65pWgbGWbMksSZEwSBhi+80DTDlluxcXsTUtHKxWwfGKcqOvgXWbB+nMCuNvIwYVqnxddjY7SKW1BRl0bLonNfhEJrL5ag3Cdc1G8tp7B9LuAiGkAljziBRKclOJy0l0lj02M4xnekZRcrEmxAFAwi63eHiW4+foDg7jYtqC3x3/NaB8ZgUH2ixj/n8xDEjiS10UPzoexvtSCnjsygjRIv1SPsQFqHk5rjvk9sTasFIWESwkCrRsFiEN9Il8Xzop7uUFayJeMPXvcvlq48epWfEyc/+bBuZaVaqC2M7KdfcPx5b/zkkv6AXZjI+6aYvhtFGMwhR0N9tHWJFaTZZ6dbkFXOIOHdNolFdmMm5Pofvtd3h4n9fbwyetCvG4+NU1wg56VafWyiR0L2g728e4OZtVT5r3JaaQlluui8aJZo4p9x0Dk/EwUJP3rBFwHdTjXglYLiEIHCuaTfvNA2w05u7JanRiaDvWFbI6e5RX+GNn756jn/6wymePR6kAEasLfTuEdaU5yTkTV/Xgj4+Oc2oc3pOxsOawixaY2Chtw+OI2WMI1yAWPsIY422gh7YujvYMsjElJs9K3WQp18HLheAy1YpsfGvnuljctrD7w4pWbt//mYTzf1j8wt7DCdFpZSc7hpNyAlR0LkPXV2+XTYrWmFpUSavn41uxSSPR/LQO0p8e22sY3qT3OWixhhHvBIwXEKwWF+r78dqEexYrjcLPTknRUFJS1uWm84r9b1k26wMjE3y3jWlvHS6l2t/+Dpjk24O/O0VFM8ObojhE2z74ASjrmnWJGDIIujcQp+vRuLSwkx6Rlw4p9xR2Y+Uki88fJj/faOJmy6sYlOsE94nuaBnpVspzEqjbSBeFnpwi/X1s31cWFOQnAuJZqMTl4sQgstWlfJafT/ff6GeijwbP/jIZvIzU7F6k6Od6Q6QYjeG4+N8DvTEtNANIehL8mbewVUf96LqFvrxwL5WnjzSyVeuXMV/3LQp9iW8klzQQYkz1sJC9wQ4Zz0jTk50jnDJKh24W0A3gg5wxboyHK5pRp1T/MP1G8jLSOX5L13CU5/bDSiFvOfgn146yk8op7u9S/7LEtNC14E5Mj+qoJcGsNBBiXRZucgL0zk0wT89dZJLV5Xw2ctXxDkML3kfp6sKMnzhXzHHb1CPOSeZfcV/8EI9Vovg2kQtWBEuOnG5AFyxtpT/++wu1pXnkmZV7E91wVdRVhpnukfmfml2PvgojsnT3SPUFGaSlaBPcjq30F1kpqWQM+vkq5OW/iFRkfLG2X5c0x6+ee3a+BXX1cGArSrIpH1oIj5pdP3O1+jEzBXCxzuGefhAG7e/pzb2cx/xQkcWuhCCzdX5PjH3Z015zsIul9l/R4FTCTwhCroXdCdlubY5VnNBVhq1RZkcaBlc9D4OtgySn5nKipLsRf9WyOhgwFYVZDA57aE/DrHoU+7zGfvGXVNMelcL//ZAGx/92V4KM9P4/Pt0VNNcJ1EuwVhdlkt9j2NuXHqMxsf45DTN9sReQax7QZ8vwdL2ukL2Nw8s2kI81DrIlur8+FnnoHRSYTn/dxJS7U2+1BaH0MWWfuVJzIMF6fHw1rl+TnaO8LVHj7JmSS4Pf2ZnbFM1xBsd9I9QWLMkh4kp99w1JTE6/jPd3iX/CRrhAroXdBdL8gInWNpeV8TQ+BRneyN3uwxPKN+/sCaGuc9no1pfFq8bKUkHrLrKLh4To/Wqn9ViJcWiVJR6YF8L6VYL9/zZhawojePTVVyQSd8/QkHNRT7Hjy49548/ivNMxzu9ES6myyX+SCnp9rpcArG9Vqkm9E7zQMT7eLdVcdlsjUFOmHnRiaBXegU9WpFGC9HQoyTdEilWCjOtvFrfx2/3t/EnF1SQn5kW8/3HHX9BS9L+EQqrynIQAs50+xllUhKLG9rA2CT//cezrCjNTsgl/yq6FfThCcVXOp+gVxdmsCTXxjtNkQv6oVYlmdMF1fkR/0bYqB00yQdsZpqVZcVZvNHQH9P9eDySkx1DAAiLldz0FGqKMpn2SD528dKY7lszZgh6ck6ah0JGWgqV+RkzgxtiZPB887FjDI1P8V8f2Rxf92qY6FbQfatE56kJKYRgW20BhxYxMXqoZZA1S3LjG8LkE/SUma+TkA9tqWRv40BM3S6PHmyna8j7+5YULHj43s0XcNflK9gczxtxPJEeXfSPUFhekj1L0KM/PianPTx3opuP76xhQ6wXDS4S3Qp69zyrRP2pLcqie8QZPHtbANweyeG2IbbW5EfaxMiYY6EnrwV2w5ZKAB4/3BmT3x9xTvHvz50+X1nGYgXp4aLaQv76A6sTMrlSVIiRDzkRWV6STWPfmF9ww+Is9Mlpjy8KSqV1YAyPhA2Vies7V9GtoKsz3wv5u8rzbbg9kt7R8CvQ1/eM4nBNx3dCFHTjcgElSdf2ukJ+d6g9Jr//01fOYR+b5I7dtcobFmtS3wBDxiA+dIDlpVlMTLnp8hpwizV4/vqRI+z41z/y2wPn6w6f61OqkNUVJ/7kuW4FvalvjIzUlDmJufypyFPEvnMofEE/pMWEKJzvsEIfj9RXrV9CY98YXcPRDV/sGXHy8zebuP6CCpYXe9MZi5SkP18hIT266R/BWO5d/3FOjVZb5Pg43jnMyMQUX3v0KC+d7gGg0Svoy0oSf+GZbgW92T5GbXHWghMY5fmK2HdGUFn8UMsQxdlpvjQCccNngahxtsltcW5Zmg/A4dahqP7uj15qwO2RfPnK1TPPmc4FDlD6hEX/cejgJ+h9swQ9guOXUtI5NMFtO2qoyLPxs9eaAGjqd1CcnU6uLfHXKuhW0Jv6x1gWZCl3uddCj8Q6PNQ6yJalBRr4YfURtqiyriKXtBQLh9uGovabbo/kyaOdXLepQinW7f8YnuQ3wJCQxohDByjOVur3zhX08F0ug+NTOKc8LC3M5BO7anm70c7xjmEa+4JrSaKgS0GfcntoHRintnhh6znXZiUrLSVsl8vg2CRN/WPxd7eArnzoAOnWFNZV5PJuFAX9aPsQQ+NTvHeNUiBhpqAn9/kKCQP50IUQLC/JomG2yyWC41ef1CvyM/jIRUvJTEvhZ6830tg/lhTuFtCpoLcPTuD2yKCTGEIIyvMzwrbQG/sVn5omVb91srDIn83V+RxrH2baHZ1jeeVMHxYBu1cUK2+Ygq5rlNBFZUxGQ9Ar8zPIy0jlth01PHmkk4GxSVPQtaTJm7ujLoTHpIr8DLqGw7PQWweUzlMdb/856CoOXWXL0nwmptyc6YlOOt1X6/u4oDqfgizvKlD/c6aD8xWUGXHo+ncx1RZn0TfqYsw17WfwhD8+VEFX59bu2LPMl+VxWRJEuECIgi6EuEoIcUYI0SCE+MYC2/2pEEIKIbZFr4nh0+gLMwpB0PNsYbtcWu0TCLFwSGTMmG2B6CDOWF3gs38Rq3ZVBsYmOdI+5KtHCcx8qjGMoCf/OoVQUQvWtA6ML+oJtnPYSZrVQpHXECjJSedjF9cAJE2+n6CCLoRIAe4GrgbWAbcKIdYF2C4H+AKwL9qNDJdm+xh5GakUZAaflS7Py6Df4cI1HXo5utaBcZbk2rClpiymmZGhMx86KAVH1pbn8tD+NuQiBejh/W1ICVeuKzv/5gxB17/AGc3lotY3aLGPLWp8dAxNUJmfMSPQ4SvvX8W9t29Lmlz5oVjo24EGKWWjlHISeAi4PsB2/wh8Fwg/qDvKNPUrIYuhRKCoj1c9w6Hn5W4dGNPG3QK6i0MHZS7j9p01nO4eZX9z5KkYnFNu7n2jiT0ri1lX4beqz/+c6eB8BcVAceigFH0HaLaPL2p8dA5NUJE/c91KZpqV960tm+cbiUcogl4JtPm9bve+50MIsRWollL+YaEfEkLcKYQ4IIQ40NfXF3ZjQ+VMt4NVIT4i+RYXhTEx2jowTo3Wgq4jHzrA9ZsrybVZ+dVbzRF9v2/UxQ9eqKff4eIvL1s+80PD+dCl7vrHQuTaUinMSqPFX9AjmEPoHJrw6UGysuhJUSGEBfg+8JVg20op75FSbpNSbispiU1BXrvDRb/D5cuVHAzV/xawlFUAnFNuekZc8V9QpLKIDpvIZKSl8KEtlbx4qmdOLo1g2B0urvj+q/zPa41ctrqEncuKZm5gOEE3TnIulZqizFkul/COf8rtoXfURUW+/gW9A6j2e13lfU8lB9gAvCKEaAZ2AE9oNTFa36NEuKwKsfhzdWEmNUWZvFof2hODmr9bfcyLOzoMW1TZuawI17SHYx3DYX1vf/MgwxNT/PS2C/nFJy6a62qb4VfVxw1wYYyzsEilpjBzloUeXtBA97ATKZWQxWQmFEHfD6wUQtQJIdKAW4An1A+llMNSymIpZa2UshbYC3xQSnkgJi0Oglq9JJwY8UtXlfDWuX6cU8EnRtWkX9pb6PobsNu8RUf2h1l05N22QVJTBJetLgk8b2LGoeuemqIsOocncE1768eGefwnvNWIlpcmx+TnfAQVdCnlNHAX8BxwCvitlPKEEOI7QogPxrqB4XKmx0F+Ziol89QSDcRlq0twTnlCKnbRYjcFPVaU5KSzrDgr7PDFw61DrKvImz/qyBR03VNTlImU0KXm1g/z+N9pGiDdamFjZX5sGhgnQvKhSymfllKuklIul1L+s/e9b0kpnwiw7WVaWeegWOiry3LCyrGyc1kxaVYLr5wJ7nZpto+RnW6lMEuj0mVzFk7oy4VwUW0hB1oGQy7ePe32cLR9mC0LFqvwO2dGEDh/H7ohXEyKhQ7MKGYChC7ozXa2Li3wLSRKVpK79bOQUlLf4wh5QlQlIy2F9ywv4tnjXUGXnx9pH2ZDZa52xRF0bKEDbKst8BXfDoX6HgcTU25f1saAGNpCN4ag13rntDoGvSkAwhgfI84pTnaOsL2uMFbNixu6EvSOoQkcrumwBR3g1u1L6Rx28uKpnnm3cU65Odk5zOZqDZJyqegwDt2fHd4IlddCnKR+t02JW1+wnJwqakKfTzVzMFgcOkBhVhrZ6VY6VUEP4/gPtgzikXCxKeiJxb5Gxfe6KQI/2BVry6jMz+AXbzbPu82JzhGm3HJhazDW6DQOXaW6MJP1Fbk8fbwrpO0Ptw5RmBUkL73Oz9kcDBi2KISgpiiTruHwXS7vNA2QmiLYokX21CijK0F/8VQPZbnprPdfJRgiKRbB7e+pYV/TAG/OU4n+XW+VooX9tTFG5y4XgGs2lvNu61BIhUcOtw2xuTp/YReYAc7ZDAyUD92fmqJMuge9fSYMl9O+RjubqvLJSNMglUeU0Y2gO6fcvFrfx/vWli1YpWghPnpxDctLsvjsrw/x4skeHnu3nX948gRveQX+cNsQlfkZlC5QeDr26HtSFODqDUsAePZ4d8DPnz/RzXX//Tq9o04a+hwLu1tAt4ux5sVgK0VVaoqy6B2ZbaEvfK0nJt0cbR/Whf8cdCToexvtjE+6uXIReRey06387+0XISV8+r4DfOnhI/zizWbuuO8A+xrtHGwZZLOW7hYwhLW5rCSbNUtyePxwR8BkXa/U93G8Y4Qf/vEsUhLcBWaAczYDA4YtgjIx6vGEd63fbR1k2iN1I+jW4JskB08f6yIzLYWdy4uCb7wAdcVZPP+lS2jsG6MoO42sdCs33P0mH7lnLwAfWL8kGs2NHIOI063bl/L3T5zgYMugb8GRSoN3NfBv3lFSDG2qyl/4xwxyznwYVNCXFmZhCbNE476mASwCLqxJfv856ETQz3SP8rtDHXzs4qVRSWlblmujzM+t8ss/387jhzu4YWsla5aE75+PKjrMhx6Im7dV8YMX6/mf1xpnCLqUkvpeJe+O2yNZUZpNXkaQNMk6TpcQEAOGLQLekpPhXet3mgZYV5GbFAWgQyHpXS5SSv7xqZNkp1v50hWrYrKPdRW5/M01a7UXcwiwsEif4pSZZuXPdtTw4qkezvpVMup3TDI0PsUH1iuutaD+czCjXAxCWY6NdNWeC+H4J6c9HGodZHvt4p7qE4mkFfQ/egf6z15v5I2Gfr585arzJcf0jM7j0P35xK46stKs/Ofz9b73znqt849eXMONWyu56cKq4D9koHMGzIpDN46FbrEIKvK8KT9CuNbHOoZwTXu4eJk+/OeQpC6Xhl4Hn/rVASxCecC6dmM5H99Ro3Wz4oOBrM3CrDTu2LOMH7xYz/1vN5ORZsXhnAKU5GuXfnhzaD9koHMGGNZCB6jMS4cxQjr+fd6cQRfVmoKuKQ/vb8VqEXz4omr6R1187+YLIg5VTDoMNsH36T113L+3hb97/AQAZbnp5NislIaRfG2uD13vVqs0ztPILNaXZ0MnjLgkubDg8b/TNMCqsmzt8jLFgKQT9MlpD7871MEVa8v4lxs2at2c+GOwCb6sdCuP/MVO7A4X33+hnrfO2bmwpiC8XDoGmUgGZs2xCN33j9lsXZoHB6F50MUmYL5rPe32cKB5kA9tqYhn82JO0vnQXzjZw8DYJLdsrw6+sR4xmvsAJZR0W20h/3LDRtKtlrBy3QPGOme++QKL8k/PxxqASq8P/ZzdWyN4nqexU12jOFzTbK/Tz4QoJKGFDvCe5UXsWRmbEnYJzxyXi46tzVnUFmfx1Od2U5wdhrsFjOWm8gm6MKSgC+94aLQ7QTDv8e9rsgP6SMjlT9IJ+rWbyrl2U7nWzdAOAws6wMoQSwvOxEBuqtkWup7dSwFRjnd8Gkhl3mv9ZkM/y4qzZqw30QNJ53IxPEayNqOFkc6ZwV0u6vFOM797zTXtZm/jAJes0t9TvinoyYYvt7f30hltwEaCv8j5v9YjvmMTittFz8caCO/xpqbOf/M+0DzIxJSbPSuL49myuGAKerJhpAm+aGGkczbHQjeYy8V7/MU5mTNeg5Iqom1gnNfO9pGaInzFVPRE0vnQDY+R3AfRwkjnzPAuF+UGVpKXCaMgPR7UANf73m7mH548SVqKha1LC8hK15/8mRZ60mGgCb5oYaSFRf4uOQO7XErzlKLRI85J30dPH+uiLDedinwbfxpKyogkRH+3KL1jJGszWhgpMsjwFrpyvGX52QB0D42T6fYw6pzmYMsgd713JV++MjZJ/BIBU9CTjdn+YMOFpUWAkSaSZ1joRvShK8e7xCvoTx7u4H9ffY4PrF+CR7KoAjjJgOlySTaMZG1GC+nxi8tG54Ju7IVF6vHmZCqLz9oHxgB4/HAnZbnpbKhMgBTYMcQU9GTDdLmEjyEF3dguF5GiFKxYsySLP37lMtYsyeGWi5aGlwMoCTFdLsmG0XJ7RwPpwReX7XutU/wtdAMm55o9Pj6zpxaRn8EzX9ijYaPihynoyYZBKhZFFdNCNw6z5pjU3C56t8xVTJdLsmGkRTLRwtCCbrA5FoOPD1PQkw3Thx4+hhZ0HR9rIAxWL2A2pqAnGwbvsBEh5UxB13Wop7mwCDBGMZMAhCToQoirhBBnhBANQohvBPj8y0KIk0KIo0KIPwohDFLgUwPMsMUImCXoej5nZvpc5T+DGjxBBV0IkQLcDVwNrANuFUKsm7XZu8A2KeUm4FHg36PdUBMvBvcRRoT0eOOyjRDlMnthkY6PNRBzxoexbmihWOjbgQYpZaOUchJ4CLjefwMp5ctSynHvy72APhMlJAKmDz18TB+6cTD4+AhF0CuBNr/X7d735uNTwDOBPhBC3CmEOCCEONDX1xd6K03OMycO3VgWSESoFjpGsND9js3IPnSDrtOI6qSoEOI2YBvwH4E+l1LeI6XcJqXcVlKiv2ohccF0uYSPaaEbB4OPj1AWFnUA1X6vq7zvzUAIcQXwTeBSKaUrOs0zmYPBHykjwhR042Dw8RGKhb4fWCmEqBNCpAG3AE/4byCE2AL8D/BBKWVv9Jtp4sNcKRo+hhZ0g7nkDG6hBxV0KeU0cBfwHHAK+K2U8oQQ4jtCiA96N/sPIBt4RAhxWAjxxDw/Z7JojB2WFRFzBF3HImf4AhcGKmYSgJByuUgpnwaenvXet/z+viLK7TKZD4MvnIgIiWmhGwWDL7wzV4omGwb3EUaELw7dCBa66UMHDDs+TEFPNgzeYSPCUD50c2ERYFiXiynoyYa/Beb/2mR+fPnQ/V/rFDMfuvK/QceHKejJhsGXNkeEoSx0swQdYEa5mCQJpsslfAwp6AZ3uZgrRU2SAoN32IgwBd04GPz4TUFPNlQPi0E7bETMFnRdh3rOnhTV87EGwODpg01BTzaMHmccEbPzoev4JjijfwiMJmhzb2g6vtYBMAU92TD6pFckzK5YpOdzZnCXg9HDNk1BTzZ8IXimoIeMubDIOBjc4DEFPdnw5fYGQ8YZR4Ih86ELg+ZymR2Hr+ObdwBMQU821Ak+MKQFEhG+SVEjCLqxXQ5GHx+moCcbczqssSyQiDDDFo2DKegmSYXBO2xEGFLQjelDnjk+jOdyMgU96ZCG7rARYdh86EYXdOM9wZqCnmxIObPDGi7OOAIMHbaobXPizuzxoedrHQBT0JMN0+USPoZ0uRi1YpGxx4cp6MmGf9iiATtsRBjaQtfxsQbCtNBNkgp1YREY0wKLhBmxyej7nJn50DHy+DAFPdkw+CNlRBhqUtToFvrsJ1gdX+sAmIKebJiCHj6G8qGbUS5GHh+moCcbBg/LighDrRQ1LXQjh/Wagp5sGLzDRoShLHRzYZFpoZskD3Nm8U0LPTizolx0HZw9y+Wi62MNhLHXaZiCnmwYPCwrIgxpoRu0AIppoZskFQbvsBFhWEE3oEvO4OPDFPRkw1xYFD5SMrPAhY7PmeEnRY39BGsKerJhFrgIH7PAhXGQHt9lNuL4MAU92TD4I2VEmAuLjIPBw3pNQU82TEEPH0P50M2FRUYeH6agJxsGt0AiwlxYZBwMvk4jJEEXQlwlhDgjhGgQQnwjwOfpQoiHvZ/vE0LURr2lJl5mFbgwWJxtRPiyLRqgcLDPQhfGvOEbfJ1GUEEXQqQAdwNXA+uAW4UQ62Zt9ilgUEq5AvgB8N1oN9TEi8EfKSPCSOfMjEM3zrUOgDWEbbYDDVLKRgAhxEPA9cBJv22uB77t/ftR4EdCCCFlDHrTofvh7R9F/WeThuF2yK9R/hYWaHod7r5Y2zYlOsNtUO09R8ICB34Op5/Stk2xYnxA+V+10F0jxuofwx2QV6X8LSzQ8lZiHv+lX4MNfxr1nw1F0CuBNr/X7cDsM+TbRko5LYQYBoqAfv+NhBB3AncCLF26NLIWZxZCyerIvqsHSlbDiiuVvy/+DJx5Wtv2JAMlq2Hzrcrfl34Neo5r255Yk78U0nNh/Y0w0mEsK7VkNay4Qvl7+51w5g/atmc+bPkx+VkRzIgWQtwEXCWl/LT39ceBi6WUd/ltc9y7Tbv39TnvNv2BfhNg27Zt8sCBA1E4BBMTExPjIIQ4KKXcFuizUCZFO4Bqv9dV3vcCbiOEsAJ5gD38ppqYmJiYREoogr4fWCmEqBNCpAG3AE/M2uYJ4Hbv3zcBL8XEf25iYmJiMi9Bfehen/hdwHNACvBzKeUJIcR3gANSyieAe4H7hRANwACK6JuYmJiYxJFQJkWRUj4NPD3rvW/5/e0Ebo5u00xMTExMwsFcKWpiYmKiE0xBNzExMdEJpqCbmJiY6ART0E1MTEx0QtCFRTHbsRB9QEuEXy9m1ipUkzmY52hhzPMTHPMcLYxW56dGSlkS6APNBH0xCCEOzLdSykTBPEcLY56f4JjnaGES8fyYLhcTExMTnWAKuomJiYlOSFZBv0frBiQB5jlaGPP8BMc8RwuTcOcnKX3oJiYmJiZzSVYL3cTExMRkFqagm5iYmOiEpBP0YAWrjYgQolkIcUwIcVgIccD7XqEQ4gUhxFnv/wVatzOeCCF+LoTo9RZfUd8LeE6Ewg+9feqoEGKrdi2PD/Ocn28LITq8/eiwEOIav8/+xnt+zgghPqBNq+OHEKJaCPGyEOKkEOKEEOIL3vcTug8llaCHWLDaqFwupdzsFxf7DeCPUsqVwB+9r43EL4GrZr033zm5Gljp/Xcn8JM4tVFLfsnc8wPwA28/2uzNsop3jN0CrPd+58fesahnpoGvSCnXATuAz3rPQ0L3oaQSdPwKVkspJwG1YLXJXK4HfuX9+1fAh7RrSvyRUr6Gkpvfn/nOyfXAfVJhL5AvhCiPS0M1Yp7zMx/XAw9JKV1SyiagAWUs6hYpZZeU8pD371HgFErt5ITuQ8km6IEKVldq1JZEQgLPCyEOegtxA5RJKbu8f3cDZdo0LaGY75yY/eo8d3ldBj/3c9MZ+vwIIWqBLcA+ErwPJZugmwRmt5RyK8pj32eFEJf4f+gtB2jGp/phnpOA/ARYDmwGuoD/1LQ1CYAQIhv4HfBFKeWI/2eJ2IeSTdBDKVhtOKSUHd7/e4HHUB6He9RHPu//vdq1MGGY75yY/QqQUvZIKd1SSg/wM867VQx5foQQqShi/qCU8vfetxO6DyWboIdSsNpQCCGyhBA56t/A+4HjzCzcfTvwuDYtTCjmOydPAH/mjVTYAQz7PVYbhlk+3xtQ+hEo5+cWIUS6EKIOZeLvnXi3L54IIQRKreRTUsrv+32U2H1ISplU/4BrgHrgHPBNrduj9T9gGXDE+++Eek6AIpRZ+LPAi0Ch1m2N83n5DYrbYArFn/mp+c4JIFCip84Bx4BtWrdfo/Nzv/f4j6IIVLnf9t/0np8zwNVatz8O52c3ijvlKHDY+++aRO9D5tJ/ExMTE52QbC4XExMTE5N5MAXdxMTERCeYgm5iYmKiE0xBNzExMdEJpqCbmJiY6ART0E1MTEx0ginoJiYmJjrh/wPGZrtpEwCzaAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(pred, label='pred')\n",
    "plt.plot(true, label='true')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "796105b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(save_dir='logs/', name='experiments_beedance1_equal_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ec5044a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/home/eromanenkova/anaconda3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "        max_epochs=10,\n",
    "        gpus=0,\n",
    "        benchmark=True,\n",
    "        #check_val_every_n_epoch=1,\n",
    "        #gradient_clip_val=gradient_clip_val,\n",
    "        logger=logger\n",
    "        #callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37eae8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eromanenkova/anaconda3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: you passed in a val_dataloader but have no validation_step. Skipping val loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | netG | NetG | 933   \n",
      "1 | netD | NetD | 585   \n",
      "------------------------------\n",
      "1.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "/home/eromanenkova/anaconda3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe9fc8d17a8485787ca758cd1c17841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eromanenkova/Intern_CPD/Alex/new_code/klcpd_code/mmd_util.py:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  sigma_samples = F.softmax(U * gumbel_lmd).matmul(sigma_var)\n",
      "/home/eromanenkova/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling .backward() or autograd.grad() the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-0e5373307c61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkl_cpd_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    456\u001b[0m         )\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;31m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    795\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_predicting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    867\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m                     \u001b[0;31m# run train epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;31m# ------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m                 \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;31m# when returning -1 from train_step, we end epoch early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_batch\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m                         \u001b[0;31m# optimizer step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_and_backward_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0mon_tpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mDeviceType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_TPU_AVAILABLE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0musing_native_amp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musing_native_amp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0musing_lbfgs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_lbfgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         )\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/core/lightning.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m         \"\"\"\n\u001b[0;32m-> 1403\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mprofiler_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"optimizer_step_and_closure_{self._optimizer_idx}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofiler_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_optimizer_step_calls\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36m__optimizer_step\u001b[0;34m(self, closure, profiler_name, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofiler_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, opt_idx, lambda_closure, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m         )\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmake_optimizer_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mrun_optimizer_step\u001b[0;34m(self, optimizer, optimizer_idx, lambda_closure, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     ) -> None:\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, lambda_closure, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtrain_step_and_backward_closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    724\u001b[0m                         \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step_and_backward_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m                             result = self.training_step_and_backward(\n\u001b[0;32m--> 726\u001b[0;31m                                 \u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhiddens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m                             )\n\u001b[1;32m    728\u001b[0m                             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_step_and_backward\u001b[0;34m(self, split_batch, batch_idx, opt_idx, optimizer, hiddens)\u001b[0m\n\u001b[1;32m    825\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"backward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m                     \u001b[0;31m# hook - call this hook only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, result, optimizer, opt_idx, *args, **kwargs)\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             result.closure_loss = self.trainer.accelerator.backward(\n\u001b[0;32m--> 865\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_accumulate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m             )\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, closure_loss, optimizer, optimizer_idx, should_accumulate, *args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         output = self.precision_plugin.backward(\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_accumulate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         )\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, model, closure_loss, optimizer, opt_idx, should_accumulate, *args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# do backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mautomatic_optimization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mclosure_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/core/lightning.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, optimizer, optimizer_idx, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \"\"\"\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_running_manual_backward\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtoggle_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling .backward() or autograd.grad() the first time."
     ]
    }
   ],
   "source": [
    "trainer.fit(kl_cpd_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd300d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 5555 (pid 19392), started 5:11:21 ago. (Use '!kill 19392' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cc0c6cf2f6024a61\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cc0c6cf2f6024a61\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 5555;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir 'logs' --port 5555"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67e21be",
   "metadata": {},
   "source": [
    "### After training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b13247f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_trained = valid_epoch(Data, Data.val_set, kl_cpd_model, args['batch_size'], Y_tst, L_tst)\n",
    "pred_trained = pred_trained / np.max(pred_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7b001934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb3e847ded0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(pred_trained, label='pred trained')\n",
    "plt.plot(pred, label='pred before training')\n",
    "plt.plot(true, label='true')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
